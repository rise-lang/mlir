{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/x-mlir": [
       "OVERVIEW: MLIR modular optimizer driver\n",
       "\n",
       "Available Dialects: acc, affine, arm_neon, arm_sve, async, avx512, gpu, linalg, llvm, llvm_arm_neon, llvm_arm_sve, llvm_avx512, nvvm, omp, pdl, pdl_interp, quant, rise, rocdl, scf, sdbm, shape, spv, std, tensor, test, tosa, vector\n",
       "USAGE: mlir-opt [options] <input file>\n",
       "\n",
       "OPTIONS:\n",
       "\n",
       "Color Options:\n",
       "\n",
       "  --color                                               - Use colors in output (default=autodetect)\n",
       "\n",
       "General options:\n",
       "\n",
       "  --allow-unregistered-dialect                          - Allow operation with no registered dialects\n",
       "  --mlir-disable-threading                              - Disabling multi-threading within MLIR\n",
       "  --mlir-elide-elementsattrs-if-larger=<uint>           - Elide ElementsAttrs with \"...\" that have more elements than the given upper limit\n",
       "  --mlir-pretty-debuginfo                               - Print pretty debug info in MLIR output\n",
       "  --mlir-print-debuginfo                                - Print debug info in MLIR output\n",
       "  --mlir-print-elementsattrs-with-hex-if-larger=<long>  - Print DenseElementsAttrs with a hex string that have more elements than the given upper limit (use -1 to disable)\n",
       "  --mlir-print-op-on-diagnostic                         - When a diagnostic is emitted on an operation, also print the operation as an attached note\n",
       "  --mlir-print-stacktrace-on-diagnostic                 - When a diagnostic is emitted, also print the stack trace as an attached note\n",
       "  -o=<filename>                                         - Output filename\n",
       "  --pass-pipeline-crash-reproducer=<string>             - Generate a .mlir reproducer file at the given output path if the pass manager crashes or fails\n",
       "  --pass-pipeline-local-reproducer                      - When generating a crash reproducer, attempt to generated a reproducer with the smallest pipeline.\n",
       "  --pass-statistics                                     - Display the statistics of each pass\n",
       "  --pass-statistics-display=<value>                     - Display method for pass statistics\n",
       "    =list                                               -   display the results in a merged list sorted by pass name\n",
       "    =pipeline                                           -   display the results with a nested pipeline view\n",
       "  --pass-timing                                         - Display the execution times of each pass\n",
       "  --pass-timing-display=<value>                         - Display method for pass timing data\n",
       "    =list                                               -   display the results in a list sorted by total time\n",
       "    =pipeline                                           -   display the results with a nested pipeline view\n",
       "  --print-ir-after=<pass-arg>                           - Print IR after specified passes\n",
       "  --print-ir-after-all                                  - Print IR after each pass\n",
       "  --print-ir-after-change                               - When printing the IR after a pass, only print if the IR changed\n",
       "  --print-ir-before=<pass-arg>                          - Print IR before specified passes\n",
       "  --print-ir-before-all                                 - Print IR before each pass\n",
       "  --print-ir-module-scope                               - When printing IR for print-ir-[before|after]{-all} always print the top-level operation\n",
       "  --run-reproducer                                      - Append the command line options of the reproducer\n",
       "  --show-dialects                                       - Print the list of registered dialects\n",
       "  --split-input-file                                    - Split the input file into pieces and process each chunk independently\n",
       "  Compiler passes to run\n",
       "    --pass-pipeline                                     -   A textual description of a pass pipeline to run\n",
       "    Passes:\n",
       "      --affine-data-copy-generate                       -   Generate explicit copying for affine memory operations\n",
       "        --fast-mem-capacity=<ulong>                     - Set fast memory space capacity in KiB (default: unlimited)\n",
       "        --fast-mem-space=<uint>                         - Fast memory space identifier for copy generation (default: 1)\n",
       "        --generate-dma                                  - Generate DMA instead of point-wise copy\n",
       "        --min-dma-transfer=<int>                        - Minimum DMA transfer size supported by the target in bytes\n",
       "        --skip-non-unit-stride-loops                    - Testing purposes: avoid non-unit stride loop choice depths for copy placement\n",
       "        --slow-mem-space=<uint>                         - Slow memory space identifier for copy generation (default: 0)\n",
       "        --tag-mem-space=<uint>                          - Tag memory space identifier for copy generation (default: 0)\n",
       "      --affine-loop-fusion                              -   Fuse affine loop nests\n",
       "        --fusion-compute-tolerance=<number>             - Fractional increase in additional computation tolerated while fusing\n",
       "        --fusion-fast-mem-space=<uint>                  - Faster memory space number to promote fusion buffers to\n",
       "        --fusion-local-buf-threshold=<ulong>            - Threshold size (KiB) for promoting local buffers to fast memory space\n",
       "        --fusion-maximal                                - Enables maximal loop fusion\n",
       "      --affine-loop-invariant-code-motion               -   Hoist loop invariant instructions outside of affine loops\n",
       "      --affine-loop-normalize                           -   Apply normalization transformations to affine loop-like ops\n",
       "      --affine-loop-tile                                -   Tile affine loop nests\n",
       "        --cache-size=<ulong>                            - Set size of cache to tile for in KiB\n",
       "        --separate                                      - Separate full and partial tiles\n",
       "        --tile-size=<uint>                              - Use this tile size for all loops\n",
       "        --tile-sizes=<uint>                             - List of tile sizes for each perfect nest (overridden by -tile-size)\n",
       "      --affine-loop-unroll                              -   Unroll affine loops\n",
       "        --unroll-factor=<uint>                          - Use this unroll factor for all loops being unrolled\n",
       "        --unroll-full                                   - Fully unroll loops\n",
       "        --unroll-full-threshold=<uint>                  - Unroll all loops with trip count less than or equal to this\n",
       "        --unroll-num-reps=<uint>                        - Unroll innermost loops repeatedly this many times\n",
       "        --unroll-up-to-factor                           - Allow unrolling up to the factor specified\n",
       "      --affine-loop-unroll-jam                          -   Unroll and jam affine loops\n",
       "        --unroll-jam-factor=<uint>                      - Use this unroll jam factor for all loops (default 4)\n",
       "      --affine-parallelize                              -   Convert affine.for ops into 1-D affine.parallel\n",
       "        --max-nested=<uint>                             - Maximum number of nested parallel loops to produce. Defaults to unlimited (UINT_MAX).\n",
       "      --affine-pipeline-data-transfer                   -   Pipeline non-blocking data transfers between explicitly managed levels of the memory hierarchy\n",
       "      --affine-super-vectorize                          -   Vectorize to a target independent n-D vector abstraction\n",
       "        --test-fastest-varying=<long>                   - Specify a 1-D, 2-D or 3-D pattern of fastest varying memory dimensions to match. See defaultPatterns in Vectorize.cpp for a description and examples. This is used for testing purposes\n",
       "        --virtual-vector-size=<long>                    - Specify an n-D virtual vector size for vectorization\n",
       "      --affine-super-vectorizer-test                    -   Tests vectorizer standalone functionality.\n",
       "      --async-parallel-for                              -   Convert scf.parallel operations to multiple async regions executed concurrently for non-overlapping iteration ranges\n",
       "        --num-concurrent-async-execute=<int>            - The number of async.execute operations that will be used for concurrent loop execution.\n",
       "      --async-ref-counting                              -   Automatic reference counting for Async dialect data types\n",
       "      --async-ref-counting-optimization                 -   Optimize automatic reference counting operations for theAsync dialect by removing redundant operations\n",
       "      --buffer-deallocation                             -   Adds all required dealloc operations for all allocations in the input program\n",
       "      --buffer-hoisting                                 -   Optimizes placement of allocation operations by moving them into common dominators and out of nested regions\n",
       "      --buffer-loop-hoisting                            -   Optimizes placement of allocation operations by moving them out of loop nests\n",
       "      --buffer-results-to-out-params                    -   Converts memref-typed function results to out-params\n",
       "      --canonicalize                                    -   Canonicalize operations\n",
       "      --convert-affine-for-to-gpu                       -   Convert top-level AffineFor Ops to GPU kernels\n",
       "        --gpu-block-dims=<uint>                         - Number of GPU block dimensions for mapping\n",
       "        --gpu-thread-dims=<uint>                        - Number of GPU thread dimensions for mapping\n",
       "      --convert-async-to-llvm                           -   Convert the operations from the async dialect into the LLVM dialect\n",
       "      --convert-elementwise-to-linalg                   -   Convert ElementwiseMappable ops to linalg\n",
       "      --convert-gpu-launch-to-vulkan-launch             -   Convert gpu.launch_func to vulkanLaunch external call\n",
       "      --convert-gpu-to-nvvm                             -   Generate NVVM operations for gpu operations\n",
       "        --index-bitwidth=<uint>                         - Bitwidth of the index type, 0 to use size of machine word\n",
       "      --convert-gpu-to-rocdl                            -   Generate ROCDL operations for gpu operations\n",
       "        --index-bitwidth=<uint>                         - Bitwidth of the index type, 0 to use size of machine word\n",
       "      --convert-gpu-to-spirv                            -   Convert GPU dialect to SPIR-V dialect\n",
       "      --convert-linalg-to-affine-loops                  -   Lower the operations from the linalg dialect into affine loops\n",
       "      --convert-linalg-to-llvm                          -   Convert the operations from the linalg dialect into the LLVM dialect\n",
       "      --convert-linalg-to-loops                         -   Lower the operations from the linalg dialect into loops\n",
       "      --convert-linalg-to-parallel-loops                -   Lower the operations from the linalg dialect into parallel loops\n",
       "      --convert-linalg-to-spirv                         -   Convert Linalg dialect to SPIR-V dialect\n",
       "      --convert-linalg-to-std                           -   Convert the operations from the linalg dialect into the Standard dialect\n",
       "      --convert-openmp-to-llvm                          -   Convert the OpenMP ops to OpenMP ops with LLVM dialect\n",
       "      --convert-parallel-loops-to-gpu                   -   Convert mapped scf.parallel ops to gpu launch operations\n",
       "      --convert-pdl-to-pdl-interp                       -   Convert PDL ops to PDL interpreter ops\n",
       "      --convert-rise-to-imperative                      -   Lower all functional primitives of the rise dialect to imperative\n",
       "      --convert-scf-to-openmp                           -   Convert SCF parallel loop to OpenMP parallel + workshare constructs.\n",
       "      --convert-scf-to-spirv                            -   Convert SCF dialect to SPIR-V dialect.\n",
       "      --convert-scf-to-std                              -   Convert SCF dialect to Standard dialect, replacing structured control flow with a CFG\n",
       "      --convert-shape-constraints                       -   Convert shape constraint operations to the standard dialect\n",
       "      --convert-shape-to-std                            -   Convert operations from the shape dialect into the standard dialect\n",
       "      --convert-spirv-to-llvm                           -   Convert SPIR-V dialect to LLVM dialect\n",
       "      --convert-std-to-llvm                             -   Convert scalar and vector operations from the Standard to the LLVM dialect\n",
       "        --data-layout=<string>                          - String description (LLVM format) of the data layout that is expected on the produced module\n",
       "        --emit-c-wrappers                               - Emit wrappers for C-compatible pointer-to-struct memref descriptors\n",
       "        --index-bitwidth=<uint>                         - Bitwidth of the index type, 0 to use size of machine word\n",
       "        --use-aligned-alloc                             - Use aligned_alloc in place of malloc for heap allocations\n",
       "        --use-bare-ptr-memref-call-conv                 - Replace FuncOp's MemRef arguments with bare pointers to the MemRef element types\n",
       "      --convert-std-to-spirv                            -   Convert Standard dialect to SPIR-V dialect\n",
       "      --convert-vector-to-llvm                          -   Lower the operations from the vector dialect into the LLVM dialect\n",
       "        --enable-arm-neon                               - Enables the use of ArmNeon dialect while lowering the vector dialect.\n",
       "        --enable-arm-sve                                - Enables the use of ArmSVE dialect while lowering the vector dialect.\n",
       "        --enable-avx512                                 - Enables the use of AVX512 dialect while lowering the vector dialect.\n",
       "        --enable-index-optimizations                    - Allows compiler to assume indices fit in 32-bit if that yields faster code\n",
       "        --reassociate-fp-reductions                     - Allows llvm to reassociate floating-point reductions for speed\n",
       "      --convert-vector-to-rocdl                         -   Lower the operations from the vector dialect into the ROCDL dialect\n",
       "      --convert-vector-to-scf                           -   Lower the operations from the vector dialect into the SCF dialect\n",
       "        --full-unroll                                   - Perform full unrolling when converting vector transfers to SCF\n",
       "      --convert-vector-to-spirv                         -   Convert Vector dialect to SPIR-V dialect\n",
       "      --copy-removal                                    -   Remove the redundant copies from input IR\n",
       "      --cse                                             -   Eliminate common sub-expressions\n",
       "      --decorate-spirv-composite-type-layout            -   Decorate SPIR-V composite type with layout info\n",
       "      --elevate-rewriting                               -   \n",
       "      --finalizing-bufferize                            -   Finalize a partial bufferization\n",
       "      --for-loop-specialization                         -   Specialize `for` loops for vectorization\n",
       "      --func-bufferize                                  -   Bufferize func/call/return ops\n",
       "      --gpu-async-region                                -   Make GPU ops async\n",
       "      --gpu-kernel-outlining                            -   Outline gpu.launch bodies to kernel functions\n",
       "      --gpu-to-llvm                                     -   Convert GPU dialect to LLVM dialect with GPU runtime calls\n",
       "        --gpu-binary-annotation=<string>                - Annotation attribute string for GPU binary\n",
       "      --inline                                          -   Inline function calls\n",
       "        --default-pipeline=<string>                     - The default optimizer pipeline used for callables\n",
       "        --max-iterations=<uint>                         - Maximum number of iterations when inlining within an SCC\n",
       "        --op-pipelines=<string>                         - Callable operation specific optimizer pipelines (in the form of `dialect.op(pipeline)`)\n",
       "      --launch-func-to-vulkan                           -   Convert vulkanLaunch external call to Vulkan runtime external calls\n",
       "      --legalize-std-for-spirv                          -   Legalize standard ops for SPIR-V lowering\n",
       "      --linalg-bufferize                                -   Bufferize the linalg dialect\n",
       "      --linalg-fold-reshape-ops-by-linearization        -   Fold TensorReshapeOps with generic/indexed generic ops by linearization\n",
       "      --linalg-fold-unit-extent-dims                    -   Remove unit-extent dimension in Linalg ops on tensors\n",
       "        --fold-one-trip-loops-only                      - Only folds the one-trip loops from Linalg ops on tensors (for testing purposes only)\n",
       "      --linalg-fusion-for-tensor-ops                    -   Fuse operations on RankedTensorType in linalg dialect\n",
       "      --linalg-generalize-named-ops                     -   Convert named ops into generic ops\n",
       "      --linalg-promote-subviews                         -   Promote subview ops to local buffers\n",
       "        --test-promote-dynamic                          - Test generation of dynamic promoted buffers\n",
       "        --test-use-alloca                               - Test generation of alloca'ed buffers.\n",
       "      --linalg-tile                                     -   Tile operations in the linalg dialect\n",
       "        --linalg-tile-sizes=<long>                      - Test generation of dynamic promoted buffers\n",
       "      --linalg-tile-to-parallel-loops                   -   Tile operations in the linalg dialect to parallel loops\n",
       "        --linalg-tile-sizes=<long>                      - Test generation of dynamic promoted buffers\n",
       "      --llvm-legalize-for-export                        -   Legalize LLVM dialect to be convertible to LLVM IR\n",
       "      --loop-coalescing                                 -   Coalesce nested loops with independent bounds into a single loop\n",
       "      --loop-invariant-code-motion                      -   Hoist loop invariant instructions outside of the loop\n",
       "      --lower-affine                                    -   Lower Affine operations to a combination of Standard and SCF operations\n",
       "      --lower-host-to-llvm                              -   Lowers the host module code and `gpu.launch_func` to LLVM\n",
       "      --memref-dataflow-opt                             -   Perform store/load forwarding for memrefs\n",
       "      --normalize-memrefs                               -   Normalize memrefs\n",
       "      --parallel-loop-collapsing                        -   Collapse parallel loops to use less induction variables\n",
       "        --collapsed-indices-0=<uint>                    - Which loop indices to combine 0th loop index\n",
       "        --collapsed-indices-1=<uint>                    - Which loop indices to combine into the position 1 loop index\n",
       "        --collapsed-indices-2=<uint>                    - Which loop indices to combine into the position 2 loop index\n",
       "      --parallel-loop-fusion                            -   Fuse adjacent parallel loops\n",
       "      --parallel-loop-specialization                    -   Specialize parallel loops for vectorization\n",
       "      --parallel-loop-tiling                            -   Tile parallel loops\n",
       "        --parallel-loop-tile-sizes=<long>               - Factors to tile parallel loops by\n",
       "      --print-cfg-graph                                 -   Print CFG graph per-Region\n",
       "      --print-op-graph                                  -   Print op graph per-Region\n",
       "      --print-op-stats                                  -   Print statistics of operations\n",
       "      --promote-buffers-to-stack                        -   Promotes heap-based allocations to automatically managed stack-based allocations\n",
       "        --bitwidth-of-index-type=<uint>                 - Bitwidth of the index type. Used for size estimation.\n",
       "        --max-alloc-size-in-bytes=<uint>                - Maximal size in bytes to promote allocations to stack.\n",
       "        --max-rank-of-allocated-memref=<uint>           - Maximal memref rank to promote dynamic buffers.\n",
       "      --quant-convert-const                             -   Converts constants followed by qbarrier to actual quantized values\n",
       "      --quant-convert-simulated-quantization            -   Converts training-time simulated quantization ops to corresponding quantize/dequantize casts\n",
       "      --remove-shape-constraints                        -   Replace all cstr_ ops with a true witness\n",
       "      --sccp                                            -   Sparse Conditional Constant Propagation\n",
       "      --scf-bufferize                                   -   Bufferize the scf dialect.\n",
       "      --shape-bufferize                                 -   Bufferize the shape dialect.\n",
       "      --shape-to-shape-lowering                         -   Legalize Shape dialect to be convertible to Standard\n",
       "      --simplify-affine-structures                      -   Simplify affine expressions in maps/sets and normalize memrefs\n",
       "      --slice-analysis-test                             -   Test Slice analysis functionality.\n",
       "      --snapshot-op-locations                           -   Generate new locations from the current IR\n",
       "        --filename=<string>                             - The filename to print the generated IR\n",
       "        --tag=<string>                                  - A tag to use when fusing the new locations with the original. If unset, the locations are replaced.\n",
       "      --spirv-lower-abi-attrs                           -   Decorate SPIR-V composite type with layout info\n",
       "      --spirv-rewrite-inserts                           -   Rewrite sequential chains of spv.CompositeInsert operations into spv.CompositeConstruct operations\n",
       "      --spirv-update-vce                                -   Deduce and attach minimal (version, capabilities, extensions) requirements to spv.module ops\n",
       "      --std-bufferize                                   -   Bufferize the std dialect\n",
       "      --std-expand                                      -   Legalize std operations to be convertible to LLVM.\n",
       "      --strip-debuginfo                                 -   Strip debug info from all operations\n",
       "      --symbol-dce                                      -   Eliminate dead symbols\n",
       "      --tensor-bufferize                                -   Bufferize the `tensor` dialect\n",
       "      --tensor-constant-bufferize                       -   Bufferize tensor constants.\n",
       "      --test-affine-data-copy                           -   Tests affine data copy utility functions.\n",
       "        --for-memref-region                             - Test copy generation for a single memref region\n",
       "        --memref-filter                                 - Enable memref filter testing in affine data copy optimization\n",
       "      --test-affine-loop-unswitch                       -   Tests affine loop unswitching / if/else hoisting\n",
       "      --test-affine-parametric-tile                     -   Tile affine loops using SSA values as tile sizes\n",
       "      --test-constant-fold                              -   Test operation constant folding\n",
       "      --test-conv-vectorization                         -   Test vectorization of convolutions\n",
       "        --tile-sizes=<long>                             - Vectorization sizes.\n",
       "      --test-convert-call-op                            -   Tests conversion of `std.call` to `llvm.call` in presence of custom types\n",
       "      --test-decompose-call-graph-types                 -   Decomposes types at call graph boundaries.\n",
       "      --test-derived-attr                               -   Run test derived attributes\n",
       "      --test-dynamic-pipeline                           -   Tests the dynamic pipeline feature by applying a pipeline on a selected set of functions\n",
       "        --dynamic-pipeline=<string>                     - The pipeline description that will run on the filtered function.\n",
       "        --op-name=<string>                              - List of function name to apply the pipeline to\n",
       "        --run-on-nested-operations                      - This will apply the pipeline on nested operations under the visited operation.\n",
       "        --run-on-parent                                 - This will apply the pipeline on the parent operation if it exist, this is expected to fail.\n",
       "      --test-expand-tanh                                -   Test expanding tanh\n",
       "      --test-extract-fixed-outer-loops                  -   test application of parametric tiling to the outer loops so that the ranges of outer loops become static\n",
       "        --test-outer-loop-sizes=<long>                  - fixed number of iterations that the outer loops should have\n",
       "      --test-func-erase-arg                             -   Test erasing func args.\n",
       "      --test-func-erase-result                          -   Test erasing func results.\n",
       "      --test-func-set-type                              -   Test FuncOp::setType.\n",
       "      --test-function-pass                              -   Test a function pass in the pass manager\n",
       "      --test-gpu-greedy-parallel-loop-mapping           -   Greedily maps all parallel loops to gpu hardware ids.\n",
       "      --test-gpu-memory-promotion                       -   Promotes the annotated arguments of gpu.func to workgroup memory.\n",
       "      --test-gpu-rewrite                                -   Applies all rewrite patterns within the GPU dialect.\n",
       "      --test-inline                                     -   Test inlining region calls\n",
       "      --test-legalize-patterns                          -   Run test dialect legalization patterns\n",
       "      --test-legalize-type-conversion                   -   Test various type conversion functionalities in DialectConversion\n",
       "      --test-legalize-unknown-root-patterns             -   Test public remapped value mechanism in ConversionPatternRewriter\n",
       "      --test-linalg-codegen-strategy                    -   Test Linalg Codegen Strategy.\n",
       "        --promote                                       - Promote the tile into a small aligned memory buffer.\n",
       "        --promote-full-tile-pad                         - Pad the small aligned memory buffer to the tile sizes.\n",
       "        --register-promote                              - Promote the register tile into a small aligned memory buffer.\n",
       "        --register-promote-full-tile-pad                - Pad the small aligned memory buffer to the tile sizes.\n",
       "        --register-tile-sizes=<long>                    - Specifies the size of the register tile that will be used  to vectorize\n",
       "        --split-transfers=<string>                      - Split vector transfers between slow (masked) and fast (unmasked) variants. Possible options are:\n",
       "                                                    \tnone: keep unsplit vector.transfer and pay the full price\n",
       "                                                    \tlinalg-copy: use linalg.fill + linalg.copy for the slow path\n",
       "                                                    \tvector-transfers: use extra small unmasked vector.transfer for the slow path\n",
       "        --tile-sizes=<long>                             - Specifies the tile sizes.\n",
       "        --unroll-vector-transfers                       - Enable full unrolling of vector.transfer operations\n",
       "        --vectorize                                     - Rewrite the linalg op as a vector operation.\n",
       "        --vectorize-contraction-to=<string>             - the type of vector op to use for linalg contractions\n",
       "      --test-linalg-fusion-transform-patterns           -   Test Linalg fusion transformation patterns by applying them greedily.\n",
       "      --test-linalg-greedy-fusion                       -   Test Linalg fusion by applying a greedy test transformation.\n",
       "      --test-linalg-hoisting                            -   Test Linalg hoisting functions.\n",
       "        --test-hoist-redundant-transfers                - Test hoisting transfer_read/transfer_write pairs\n",
       "        --test-hoist-view-allocs                        - Test hoisting alloc used by view\n",
       "      --test-linalg-tile-and-fuse                       -   Test Linalg tiling and fusion of a sequence of Linalg operations.\n",
       "        --tile-sizes=<long>                             - Tile sizes to use for ops\n",
       "      --test-linalg-transform-patterns                  -   Test Linalg transformation patterns by applying them greedily.\n",
       "        --test-affine-min-scf-canonicalization-patterns - Test affine-min + scf canonicalization patterns.\n",
       "        --test-linalg-promotion-options                 - Test promotion options\n",
       "        --test-linalg-to-vector-patterns                - Test a set of patterns that rewrite a linalg contraction in vector.contract form\n",
       "        --test-matmul-to-vector-patterns-tile-1d        - Test a fused pass that applies patterns from matmul to vectors via 1-d tiling\n",
       "        --test-matmul-to-vector-patterns-tile-2d        - Test a fused pass that applies patterns from matmul to vectors via 2-d tiling\n",
       "        --test-patterns                                 - Test a mixed set of patterns\n",
       "        --test-tile-and-distribute-options              - Test tile and distribute options\n",
       "        --test-vector-transfer-forwarding-patterns      - Test a fused pass that forwards linalg.copy to vector.transfer\n",
       "      --test-loop-fusion                                -   Tests loop fusion utility functions.\n",
       "      --test-loop-permutation                           -   Tests affine loop permutation utility\n",
       "        --permutation-map=<uint>                        - Specify the loop permutation\n",
       "      --test-loop-unrolling                             -   Tests loop unrolling transformation\n",
       "        --loop-depth=<uint>                             - Loop depth.\n",
       "        --unroll-factor=<ulong>                         - Loop unroll factor.\n",
       "        --unroll-up-to-factor                           - Loop unroll up to factor.\n",
       "      --test-mapping-to-processing-elements             -   test mapping a single loop on a virtual processor grid\n",
       "      --test-matchers                                   -   Test C++ pattern matchers.\n",
       "      --test-memref-bound-check                         -   Check memref access bounds in a Function\n",
       "      --test-memref-dependence-check                    -   Checks dependences between all pairs of memref accesses.\n",
       "      --test-memref-stride-calculation                  -   Test operation constant folding\n",
       "      --test-merge-blocks                               -   Test Merging operation in ConversionPatternRewriter\n",
       "      --test-ml-opt-pass                                -   Test ML-Opt functionality\n",
       "      --test-mlir-reducer                               -   Tests MLIR Reduce tool by generating failures\n",
       "      --test-module-pass                                -   Test a module pass in the pass manager\n",
       "      --test-opaque-loc                                 -   Changes all leaf locations to opaque locations\n",
       "      --test-options-pass                               -   Test options parsing capabilities\n",
       "        --list=<int>                                    - Example list option\n",
       "        --string=<string>                               - Example string option\n",
       "        --string-list=<string>                          - Example string list option\n",
       "      --test-pass-crash                                 -   Test a pass in the pass manager that always crashes\n",
       "      --test-patterns                                   -   Run test dialect patterns\n",
       "      --test-pdl-bytecode-pass                          -   Test PDL ByteCode functionality\n",
       "      --test-print-callgraph                            -   Print the contents of a constructed callgraph.\n",
       "      --test-print-defuse                               -   Test various printing.\n",
       "      --test-print-dominance                            -   Print the dominance information for multiple regions.\n",
       "      --test-print-liveness                             -   Print the contents of a constructed liveness information.\n",
       "      --test-print-nesting                              -   Test various printing.\n",
       "      --test-print-number-of-block-executions           -   Print the contents of a constructed number of executions analysis for all blocks.\n",
       "      --test-print-number-of-operation-executions       -   Print the contents of a constructed number of executions analysis for all operations.\n",
       "      --test-recursive-types                            -   Test support for recursive types\n",
       "      --test-remapped-value                             -   Test public remapped value mechanism in ConversionPatternRewriter\n",
       "      --test-return-type                                -   Run return type functions\n",
       "      --test-scf-for-utils                              -   test scf.for utils\n",
       "      --test-scf-if-utils                               -   test scf.if utils\n",
       "      --test-shape-function-report                      -   Test pass to report associated shape functions\n",
       "      --test-side-effects                               -   Test side effects interfaces\n",
       "      --test-sparsification                             -   Test automatic generation of sparse tensor code\n",
       "        --ind-type=<int>                                - Set the index type\n",
       "        --parallelization-strategy=<int>                - Set the parallelization strategy\n",
       "        --ptr-type=<int>                                - Set the pointer type\n",
       "        --vectorization-strategy=<int>                  - Set the vectorization strategy\n",
       "        --vl=<int>                                      - Set the vector length\n",
       "      --test-spirv-entry-point-abi                      -   Set the spv.entry_point_abi attribute on GPU kernel function within the module, intended for testing only\n",
       "        --workgroup-size=<int>                          - Workgroup size to use for all gpu.func kernels in the module, specified with x-dimension first, y-dimension next and z-dimension last. Unspecified dimensions will be set to 1\n",
       "      --test-spirv-glsl-canonicalization                -   Tests SPIR-V canonicalization patterns for GLSL extension.\n",
       "      --test-spirv-module-combiner                      -   Tests SPIR-V module combiner library\n",
       "      --test-spirv-op-availability                      -   Test SPIR-V op availability\n",
       "      --test-spirv-target-env                           -   Test SPIR-V target environment\n",
       "      --test-stats-pass                                 -   Test pass statistics\n",
       "      --test-symbol-rauw                                -   Test replacement of symbol uses\n",
       "      --test-symbol-uses                                -   Test detection of symbol uses\n",
       "      --test-trait-folder                               -   Run trait folding\n",
       "      --test-type-interfaces                            -   Test type interface support.\n",
       "      --test-vector-contraction-conversion              -   Test conversion patterns that lower contract ops in the vector dialect\n",
       "        --vector-filter-outerproduct                    - Lower vector.contract to vector.outerproduct but not for vectors of size 4.\n",
       "        --vector-flat-transpose                         - Lower 2-D vector.transpose to vector.flat_transpose\n",
       "        --vector-lower-matrix-intrinsics                - Lower vector.contract to llvm.intr.matrix.multiply\n",
       "        --vector-outerproduct                           - Lower vector.contract to vector.outerproduct\n",
       "      --test-vector-distribute-patterns                 -   Test conversion patterns to distribute vector ops in the vector dialect\n",
       "        --distribution-multiplicity=<int>               - Set the multiplicity used for distributing vector\n",
       "      --test-vector-slices-conversion                   -   Test conversion patterns that lower slices ops in the vector dialect\n",
       "      --test-vector-to-forloop                          -   Test conversion patterns to break up a vector op into a for loop\n",
       "        --distribution-multiplicity=<int>               - Set the multiplicity used for distributing vector\n",
       "      --test-vector-to-vector-conversion                -   Test conversion patterns between ops in the vector dialect\n",
       "      --test-vector-transfer-full-partial-split         -   Test conversion patterns to split transfer ops via scf.if + linalg ops\n",
       "        --use-linalg-copy                               - Split using a unmasked vector.transfer + linalg.fill + linalg.copy operations.\n",
       "      --test-vector-transfer-unrolling-patterns         -   Test conversion patterns to unroll transfer ops in the vector dialect\n",
       "      --test-vector-transferop-opt                      -   Test optimization transformations for transfer ops\n",
       "      --test-vector-unrolling-patterns                  -   Test conversion patterns to unroll contract ops in the vector dialect\n",
       "        --unroll-based-on-type                          - Set the unroll factor based on type of the operation\n",
       "      --tosa-make-broadcastable                         -   TOSA rank Reshape to enable Broadcasting\n",
       "      --tosa-test-quant-utils                           -   TOSA Test: Exercise the APIs in QuantUtils.cpp.\n",
       "    Pass Pipelines:\n",
       "      --test-dump-pipeline                              -   Dumps the pipeline build so far for debugging purposes\n",
       "      --test-options-pass-pipeline                      -   Parses options using pass pipeline registration\n",
       "        --list=<int>                                    - Example list option\n",
       "        --string=<string>                               - Example string option\n",
       "        --string-list=<string>                          - Example string list option\n",
       "      --test-pm-nested-pipeline                         -   Test a nested pipeline in the pass manager\n",
       "      --test-textual-pm-nested-pipeline                 -   Test a nested pipeline in the pass manager\n",
       "  --test-legalize-mode=<value>                          - The legalization mode to use with the test driver\n",
       "    =analysis                                           -   Perform an analysis conversion\n",
       "    =full                                               -   Perform a full conversion\n",
       "    =partial                                            -   Perform a partial conversion\n",
       "  --verify-diagnostics                                  - Check that emitted diagnostics match expected-* lines on the corresponding line\n",
       "  --verify-each                                         - Run the verifier after each transformation pass\n",
       "\n",
       "Generic Options:\n",
       "\n",
       "  --help                                                - Display available options (--help-hidden for more)\n",
       "  --help-list                                           - Display list of available options (--help-list-hidden for more)\n",
       "  --version                                             - Display the version of this program\n",
       "\n",
       "affine-super-vectorizer-test options:\n",
       "\n",
       "  --backward-slicing                                    - Enable testing backward static slicing and topological sort functionalities\n",
       "  --compose-maps                                        - Enable testing the composition of AffineMap where each AffineMap in the composition is specified as the affine_map attribute in a constant op.\n",
       "  --forward-slicing                                     - Enable testing forward static slicing and topological sort functionalities\n",
       "  --normalize-maps                                      - Enable testing the normalization of AffineAffineApplyOp where each AffineAffineApplyOp in the composition is a single output operation.\n",
       "  --slicing                                             - Enable testing static slicing and topological sort functionalities\n",
       "  --vector-shape-ratio=<int>                            - Specify the HW vector size for vectorization\n",
       "  --vectorize-affine-loop-nest                          - Enable testing for the 'vectorizeAffineLoopNest' utility by vectorizing the outermost loops found\n",
       "\n",
       "test-loop-fusion options:\n",
       "\n",
       "  --test-loop-fusion-dependence-check                   - Enable testing of loop fusion dependence check\n",
       "  --test-loop-fusion-slice-computation                  - Enable testing of loop fusion slice computation\n",
       "  --test-loop-fusion-transformation                     - Enable testing of loop fusion transformation\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERVIEW: MLIR modular optimizer driver\n",
      "\n",
      "Available Dialects: acc, affine, arm_neon, arm_sve, async, avx512, gpu, linalg, llvm, llvm_arm_neon, llvm_arm_sve, llvm_avx512, nvvm, omp, pdl, pdl_interp, quant, rise, rocdl, scf, sdbm, shape, spv, std, tensor, test, tosa, vector\n",
      "USAGE: mlir-opt [options] <input file>\n",
      "\n",
      "OPTIONS:\n",
      "\n",
      "Color Options:\n",
      "\n",
      "  --color                                               - Use colors in output (default=autodetect)\n",
      "\n",
      "General options:\n",
      "\n",
      "  --allow-unregistered-dialect                          - Allow operation with no registered dialects\n",
      "  --mlir-disable-threading                              - Disabling multi-threading within MLIR\n",
      "  --mlir-elide-elementsattrs-if-larger=<uint>           - Elide ElementsAttrs with \"...\" that have more elements than the given upper limit\n",
      "  --mlir-pretty-debuginfo                               - Print pretty debug info in MLIR output\n",
      "  --mlir-print-debuginfo                                - Print debug info in MLIR output\n",
      "  --mlir-print-elementsattrs-with-hex-if-larger=<long>  - Print DenseElementsAttrs with a hex string that have more elements than the given upper limit (use -1 to disable)\n",
      "  --mlir-print-op-on-diagnostic                         - When a diagnostic is emitted on an operation, also print the operation as an attached note\n",
      "  --mlir-print-stacktrace-on-diagnostic                 - When a diagnostic is emitted, also print the stack trace as an attached note\n",
      "  -o=<filename>                                         - Output filename\n",
      "  --pass-pipeline-crash-reproducer=<string>             - Generate a .mlir reproducer file at the given output path if the pass manager crashes or fails\n",
      "  --pass-pipeline-local-reproducer                      - When generating a crash reproducer, attempt to generated a reproducer with the smallest pipeline.\n",
      "  --pass-statistics                                     - Display the statistics of each pass\n",
      "  --pass-statistics-display=<value>                     - Display method for pass statistics\n",
      "    =list                                               -   display the results in a merged list sorted by pass name\n",
      "    =pipeline                                           -   display the results with a nested pipeline view\n",
      "  --pass-timing                                         - Display the execution times of each pass\n",
      "  --pass-timing-display=<value>                         - Display method for pass timing data\n",
      "    =list                                               -   display the results in a list sorted by total time\n",
      "    =pipeline                                           -   display the results with a nested pipeline view\n",
      "  --print-ir-after=<pass-arg>                           - Print IR after specified passes\n",
      "  --print-ir-after-all                                  - Print IR after each pass\n",
      "  --print-ir-after-change                               - When printing the IR after a pass, only print if the IR changed\n",
      "  --print-ir-before=<pass-arg>                          - Print IR before specified passes\n",
      "  --print-ir-before-all                                 - Print IR before each pass\n",
      "  --print-ir-module-scope                               - When printing IR for print-ir-[before|after]{-all} always print the top-level operation\n",
      "  --run-reproducer                                      - Append the command line options of the reproducer\n",
      "  --show-dialects                                       - Print the list of registered dialects\n",
      "  --split-input-file                                    - Split the input file into pieces and process each chunk independently\n",
      "  Compiler passes to run\n",
      "    --pass-pipeline                                     -   A textual description of a pass pipeline to run\n",
      "    Passes:\n",
      "      --affine-data-copy-generate                       -   Generate explicit copying for affine memory operations\n",
      "        --fast-mem-capacity=<ulong>                     - Set fast memory space capacity in KiB (default: unlimited)\n",
      "        --fast-mem-space=<uint>                         - Fast memory space identifier for copy generation (default: 1)\n",
      "        --generate-dma                                  - Generate DMA instead of point-wise copy\n",
      "        --min-dma-transfer=<int>                        - Minimum DMA transfer size supported by the target in bytes\n",
      "        --skip-non-unit-stride-loops                    - Testing purposes: avoid non-unit stride loop choice depths for copy placement\n",
      "        --slow-mem-space=<uint>                         - Slow memory space identifier for copy generation (default: 0)\n",
      "        --tag-mem-space=<uint>                          - Tag memory space identifier for copy generation (default: 0)\n",
      "      --affine-loop-fusion                              -   Fuse affine loop nests\n",
      "        --fusion-compute-tolerance=<number>             - Fractional increase in additional computation tolerated while fusing\n",
      "        --fusion-fast-mem-space=<uint>                  - Faster memory space number to promote fusion buffers to\n",
      "        --fusion-local-buf-threshold=<ulong>            - Threshold size (KiB) for promoting local buffers to fast memory space\n",
      "        --fusion-maximal                                - Enables maximal loop fusion\n",
      "      --affine-loop-invariant-code-motion               -   Hoist loop invariant instructions outside of affine loops\n",
      "      --affine-loop-normalize                           -   Apply normalization transformations to affine loop-like ops\n",
      "      --affine-loop-tile                                -   Tile affine loop nests\n",
      "        --cache-size=<ulong>                            - Set size of cache to tile for in KiB\n",
      "        --separate                                      - Separate full and partial tiles\n",
      "        --tile-size=<uint>                              - Use this tile size for all loops\n",
      "        --tile-sizes=<uint>                             - List of tile sizes for each perfect nest (overridden by -tile-size)\n",
      "      --affine-loop-unroll                              -   Unroll affine loops\n",
      "        --unroll-factor=<uint>                          - Use this unroll factor for all loops being unrolled\n",
      "        --unroll-full                                   - Fully unroll loops\n",
      "        --unroll-full-threshold=<uint>                  - Unroll all loops with trip count less than or equal to this\n",
      "        --unroll-num-reps=<uint>                        - Unroll innermost loops repeatedly this many times\n",
      "        --unroll-up-to-factor                           - Allow unrolling up to the factor specified\n",
      "      --affine-loop-unroll-jam                          -   Unroll and jam affine loops\n",
      "        --unroll-jam-factor=<uint>                      - Use this unroll jam factor for all loops (default 4)\n",
      "      --affine-parallelize                              -   Convert affine.for ops into 1-D affine.parallel\n",
      "        --max-nested=<uint>                             - Maximum number of nested parallel loops to produce. Defaults to unlimited (UINT_MAX).\n",
      "      --affine-pipeline-data-transfer                   -   Pipeline non-blocking data transfers between explicitly managed levels of the memory hierarchy\n",
      "      --affine-super-vectorize                          -   Vectorize to a target independent n-D vector abstraction\n",
      "        --test-fastest-varying=<long>                   - Specify a 1-D, 2-D or 3-D pattern of fastest varying memory dimensions to match. See defaultPatterns in Vectorize.cpp for a description and examples. This is used for testing purposes\n",
      "        --virtual-vector-size=<long>                    - Specify an n-D virtual vector size for vectorization\n",
      "      --affine-super-vectorizer-test                    -   Tests vectorizer standalone functionality.\n",
      "      --async-parallel-for                              -   Convert scf.parallel operations to multiple async regions executed concurrently for non-overlapping iteration ranges\n",
      "        --num-concurrent-async-execute=<int>            - The number of async.execute operations that will be used for concurrent loop execution.\n",
      "      --async-ref-counting                              -   Automatic reference counting for Async dialect data types\n",
      "      --async-ref-counting-optimization                 -   Optimize automatic reference counting operations for theAsync dialect by removing redundant operations\n",
      "      --buffer-deallocation                             -   Adds all required dealloc operations for all allocations in the input program\n",
      "      --buffer-hoisting                                 -   Optimizes placement of allocation operations by moving them into common dominators and out of nested regions\n",
      "      --buffer-loop-hoisting                            -   Optimizes placement of allocation operations by moving them out of loop nests\n",
      "      --buffer-results-to-out-params                    -   Converts memref-typed function results to out-params\n",
      "      --canonicalize                                    -   Canonicalize operations\n",
      "      --convert-affine-for-to-gpu                       -   Convert top-level AffineFor Ops to GPU kernels\n",
      "        --gpu-block-dims=<uint>                         - Number of GPU block dimensions for mapping\n",
      "        --gpu-thread-dims=<uint>                        - Number of GPU thread dimensions for mapping\n",
      "      --convert-async-to-llvm                           -   Convert the operations from the async dialect into the LLVM dialect\n",
      "      --convert-elementwise-to-linalg                   -   Convert ElementwiseMappable ops to linalg\n",
      "      --convert-gpu-launch-to-vulkan-launch             -   Convert gpu.launch_func to vulkanLaunch external call\n",
      "      --convert-gpu-to-nvvm                             -   Generate NVVM operations for gpu operations\n",
      "        --index-bitwidth=<uint>                         - Bitwidth of the index type, 0 to use size of machine word\n",
      "      --convert-gpu-to-rocdl                            -   Generate ROCDL operations for gpu operations\n",
      "        --index-bitwidth=<uint>                         - Bitwidth of the index type, 0 to use size of machine word\n",
      "      --convert-gpu-to-spirv                            -   Convert GPU dialect to SPIR-V dialect\n",
      "      --convert-linalg-to-affine-loops                  -   Lower the operations from the linalg dialect into affine loops\n",
      "      --convert-linalg-to-llvm                          -   Convert the operations from the linalg dialect into the LLVM dialect\n",
      "      --convert-linalg-to-loops                         -   Lower the operations from the linalg dialect into loops\n",
      "      --convert-linalg-to-parallel-loops                -   Lower the operations from the linalg dialect into parallel loops\n",
      "      --convert-linalg-to-spirv                         -   Convert Linalg dialect to SPIR-V dialect\n",
      "      --convert-linalg-to-std                           -   Convert the operations from the linalg dialect into the Standard dialect\n",
      "      --convert-openmp-to-llvm                          -   Convert the OpenMP ops to OpenMP ops with LLVM dialect\n",
      "      --convert-parallel-loops-to-gpu                   -   Convert mapped scf.parallel ops to gpu launch operations\n",
      "      --convert-pdl-to-pdl-interp                       -   Convert PDL ops to PDL interpreter ops\n",
      "      --convert-rise-to-imperative                      -   Lower all functional primitives of the rise dialect to imperative\n",
      "      --convert-scf-to-openmp                           -   Convert SCF parallel loop to OpenMP parallel + workshare constructs.\n",
      "      --convert-scf-to-spirv                            -   Convert SCF dialect to SPIR-V dialect.\n",
      "      --convert-scf-to-std                              -   Convert SCF dialect to Standard dialect, replacing structured control flow with a CFG\n",
      "      --convert-shape-constraints                       -   Convert shape constraint operations to the standard dialect\n",
      "      --convert-shape-to-std                            -   Convert operations from the shape dialect into the standard dialect\n",
      "      --convert-spirv-to-llvm                           -   Convert SPIR-V dialect to LLVM dialect\n",
      "      --convert-std-to-llvm                             -   Convert scalar and vector operations from the Standard to the LLVM dialect\n",
      "        --data-layout=<string>                          - String description (LLVM format) of the data layout that is expected on the produced module\n",
      "        --emit-c-wrappers                               - Emit wrappers for C-compatible pointer-to-struct memref descriptors\n",
      "        --index-bitwidth=<uint>                         - Bitwidth of the index type, 0 to use size of machine word\n",
      "        --use-aligned-alloc                             - Use aligned_alloc in place of malloc for heap allocations\n",
      "        --use-bare-ptr-memref-call-conv                 - Replace FuncOp's MemRef arguments with bare pointers to the MemRef element types\n",
      "      --convert-std-to-spirv                            -   Convert Standard dialect to SPIR-V dialect\n",
      "      --convert-vector-to-llvm                          -   Lower the operations from the vector dialect into the LLVM dialect\n",
      "        --enable-arm-neon                               - Enables the use of ArmNeon dialect while lowering the vector dialect.\n",
      "        --enable-arm-sve                                - Enables the use of ArmSVE dialect while lowering the vector dialect.\n",
      "        --enable-avx512                                 - Enables the use of AVX512 dialect while lowering the vector dialect.\n",
      "        --enable-index-optimizations                    - Allows compiler to assume indices fit in 32-bit if that yields faster code\n",
      "        --reassociate-fp-reductions                     - Allows llvm to reassociate floating-point reductions for speed\n",
      "      --convert-vector-to-rocdl                         -   Lower the operations from the vector dialect into the ROCDL dialect\n",
      "      --convert-vector-to-scf                           -   Lower the operations from the vector dialect into the SCF dialect\n",
      "        --full-unroll                                   - Perform full unrolling when converting vector transfers to SCF\n",
      "      --convert-vector-to-spirv                         -   Convert Vector dialect to SPIR-V dialect\n",
      "      --copy-removal                                    -   Remove the redundant copies from input IR\n",
      "      --cse                                             -   Eliminate common sub-expressions\n",
      "      --decorate-spirv-composite-type-layout            -   Decorate SPIR-V composite type with layout info\n",
      "      --elevate-rewriting                               -   \n",
      "      --finalizing-bufferize                            -   Finalize a partial bufferization\n",
      "      --for-loop-specialization                         -   Specialize `for` loops for vectorization\n",
      "      --func-bufferize                                  -   Bufferize func/call/return ops\n",
      "      --gpu-async-region                                -   Make GPU ops async\n",
      "      --gpu-kernel-outlining                            -   Outline gpu.launch bodies to kernel functions\n",
      "      --gpu-to-llvm                                     -   Convert GPU dialect to LLVM dialect with GPU runtime calls\n",
      "        --gpu-binary-annotation=<string>                - Annotation attribute string for GPU binary\n",
      "      --inline                                          -   Inline function calls\n",
      "        --default-pipeline=<string>                     - The default optimizer pipeline used for callables\n",
      "        --max-iterations=<uint>                         - Maximum number of iterations when inlining within an SCC\n",
      "        --op-pipelines=<string>                         - Callable operation specific optimizer pipelines (in the form of `dialect.op(pipeline)`)\n",
      "      --launch-func-to-vulkan                           -   Convert vulkanLaunch external call to Vulkan runtime external calls\n",
      "      --legalize-std-for-spirv                          -   Legalize standard ops for SPIR-V lowering\n",
      "      --linalg-bufferize                                -   Bufferize the linalg dialect\n",
      "      --linalg-fold-reshape-ops-by-linearization        -   Fold TensorReshapeOps with generic/indexed generic ops by linearization\n",
      "      --linalg-fold-unit-extent-dims                    -   Remove unit-extent dimension in Linalg ops on tensors\n",
      "        --fold-one-trip-loops-only                      - Only folds the one-trip loops from Linalg ops on tensors (for testing purposes only)\n",
      "      --linalg-fusion-for-tensor-ops                    -   Fuse operations on RankedTensorType in linalg dialect\n",
      "      --linalg-generalize-named-ops                     -   Convert named ops into generic ops\n",
      "      --linalg-promote-subviews                         -   Promote subview ops to local buffers\n",
      "        --test-promote-dynamic                          - Test generation of dynamic promoted buffers\n",
      "        --test-use-alloca                               - Test generation of alloca'ed buffers.\n",
      "      --linalg-tile                                     -   Tile operations in the linalg dialect\n",
      "        --linalg-tile-sizes=<long>                      - Test generation of dynamic promoted buffers\n",
      "      --linalg-tile-to-parallel-loops                   -   Tile operations in the linalg dialect to parallel loops\n",
      "        --linalg-tile-sizes=<long>                      - Test generation of dynamic promoted buffers\n",
      "      --llvm-legalize-for-export                        -   Legalize LLVM dialect to be convertible to LLVM IR\n",
      "      --loop-coalescing                                 -   Coalesce nested loops with independent bounds into a single loop\n",
      "      --loop-invariant-code-motion                      -   Hoist loop invariant instructions outside of the loop\n",
      "      --lower-affine                                    -   Lower Affine operations to a combination of Standard and SCF operations\n",
      "      --lower-host-to-llvm                              -   Lowers the host module code and `gpu.launch_func` to LLVM\n",
      "      --memref-dataflow-opt                             -   Perform store/load forwarding for memrefs\n",
      "      --normalize-memrefs                               -   Normalize memrefs\n",
      "      --parallel-loop-collapsing                        -   Collapse parallel loops to use less induction variables\n",
      "        --collapsed-indices-0=<uint>                    - Which loop indices to combine 0th loop index\n",
      "        --collapsed-indices-1=<uint>                    - Which loop indices to combine into the position 1 loop index\n",
      "        --collapsed-indices-2=<uint>                    - Which loop indices to combine into the position 2 loop index\n",
      "      --parallel-loop-fusion                            -   Fuse adjacent parallel loops\n",
      "      --parallel-loop-specialization                    -   Specialize parallel loops for vectorization\n",
      "      --parallel-loop-tiling                            -   Tile parallel loops\n",
      "        --parallel-loop-tile-sizes=<long>               - Factors to tile parallel loops by\n",
      "      --print-cfg-graph                                 -   Print CFG graph per-Region\n",
      "      --print-op-graph                                  -   Print op graph per-Region\n",
      "      --print-op-stats                                  -   Print statistics of operations\n",
      "      --promote-buffers-to-stack                        -   Promotes heap-based allocations to automatically managed stack-based allocations\n",
      "        --bitwidth-of-index-type=<uint>                 - Bitwidth of the index type. Used for size estimation.\n",
      "        --max-alloc-size-in-bytes=<uint>                - Maximal size in bytes to promote allocations to stack.\n",
      "        --max-rank-of-allocated-memref=<uint>           - Maximal memref rank to promote dynamic buffers.\n",
      "      --quant-convert-const                             -   Converts constants followed by qbarrier to actual quantized values\n",
      "      --quant-convert-simulated-quantization            -   Converts training-time simulated quantization ops to corresponding quantize/dequantize casts\n",
      "      --remove-shape-constraints                        -   Replace all cstr_ ops with a true witness\n",
      "      --sccp                                            -   Sparse Conditional Constant Propagation\n",
      "      --scf-bufferize                                   -   Bufferize the scf dialect.\n",
      "      --shape-bufferize                                 -   Bufferize the shape dialect.\n",
      "      --shape-to-shape-lowering                         -   Legalize Shape dialect to be convertible to Standard\n",
      "      --simplify-affine-structures                      -   Simplify affine expressions in maps/sets and normalize memrefs\n",
      "      --slice-analysis-test                             -   Test Slice analysis functionality.\n",
      "      --snapshot-op-locations                           -   Generate new locations from the current IR\n",
      "        --filename=<string>                             - The filename to print the generated IR\n",
      "        --tag=<string>                                  - A tag to use when fusing the new locations with the original. If unset, the locations are replaced.\n",
      "      --spirv-lower-abi-attrs                           -   Decorate SPIR-V composite type with layout info\n",
      "      --spirv-rewrite-inserts                           -   Rewrite sequential chains of spv.CompositeInsert operations into spv.CompositeConstruct operations\n",
      "      --spirv-update-vce                                -   Deduce and attach minimal (version, capabilities, extensions) requirements to spv.module ops\n",
      "      --std-bufferize                                   -   Bufferize the std dialect\n",
      "      --std-expand                                      -   Legalize std operations to be convertible to LLVM.\n",
      "      --strip-debuginfo                                 -   Strip debug info from all operations\n",
      "      --symbol-dce                                      -   Eliminate dead symbols\n",
      "      --tensor-bufferize                                -   Bufferize the `tensor` dialect\n",
      "      --tensor-constant-bufferize                       -   Bufferize tensor constants.\n",
      "      --test-affine-data-copy                           -   Tests affine data copy utility functions.\n",
      "        --for-memref-region                             - Test copy generation for a single memref region\n",
      "        --memref-filter                                 - Enable memref filter testing in affine data copy optimization\n",
      "      --test-affine-loop-unswitch                       -   Tests affine loop unswitching / if/else hoisting\n",
      "      --test-affine-parametric-tile                     -   Tile affine loops using SSA values as tile sizes\n",
      "      --test-constant-fold                              -   Test operation constant folding\n",
      "      --test-conv-vectorization                         -   Test vectorization of convolutions\n",
      "        --tile-sizes=<long>                             - Vectorization sizes.\n",
      "      --test-convert-call-op                            -   Tests conversion of `std.call` to `llvm.call` in presence of custom types\n",
      "      --test-decompose-call-graph-types                 -   Decomposes types at call graph boundaries.\n",
      "      --test-derived-attr                               -   Run test derived attributes\n",
      "      --test-dynamic-pipeline                           -   Tests the dynamic pipeline feature by applying a pipeline on a selected set of functions\n",
      "        --dynamic-pipeline=<string>                     - The pipeline description that will run on the filtered function.\n",
      "        --op-name=<string>                              - List of function name to apply the pipeline to\n",
      "        --run-on-nested-operations                      - This will apply the pipeline on nested operations under the visited operation.\n",
      "        --run-on-parent                                 - This will apply the pipeline on the parent operation if it exist, this is expected to fail.\n",
      "      --test-expand-tanh                                -   Test expanding tanh\n",
      "      --test-extract-fixed-outer-loops                  -   test application of parametric tiling to the outer loops so that the ranges of outer loops become static\n",
      "        --test-outer-loop-sizes=<long>                  - fixed number of iterations that the outer loops should have\n",
      "      --test-func-erase-arg                             -   Test erasing func args.\n",
      "      --test-func-erase-result                          -   Test erasing func results.\n",
      "      --test-func-set-type                              -   Test FuncOp::setType.\n",
      "      --test-function-pass                              -   Test a function pass in the pass manager\n",
      "      --test-gpu-greedy-parallel-loop-mapping           -   Greedily maps all parallel loops to gpu hardware ids.\n",
      "      --test-gpu-memory-promotion                       -   Promotes the annotated arguments of gpu.func to workgroup memory.\n",
      "      --test-gpu-rewrite                                -   Applies all rewrite patterns within the GPU dialect.\n",
      "      --test-inline                                     -   Test inlining region calls\n",
      "      --test-legalize-patterns                          -   Run test dialect legalization patterns\n",
      "      --test-legalize-type-conversion                   -   Test various type conversion functionalities in DialectConversion\n",
      "      --test-legalize-unknown-root-patterns             -   Test public remapped value mechanism in ConversionPatternRewriter\n",
      "      --test-linalg-codegen-strategy                    -   Test Linalg Codegen Strategy.\n",
      "        --promote                                       - Promote the tile into a small aligned memory buffer.\n",
      "        --promote-full-tile-pad                         - Pad the small aligned memory buffer to the tile sizes.\n",
      "        --register-promote                              - Promote the register tile into a small aligned memory buffer.\n",
      "        --register-promote-full-tile-pad                - Pad the small aligned memory buffer to the tile sizes.\n",
      "        --register-tile-sizes=<long>                    - Specifies the size of the register tile that will be used  to vectorize\n",
      "        --split-transfers=<string>                      - Split vector transfers between slow (masked) and fast (unmasked) variants. Possible options are:\n",
      "                                                    \tnone: keep unsplit vector.transfer and pay the full price\n",
      "                                                    \tlinalg-copy: use linalg.fill + linalg.copy for the slow path\n",
      "                                                    \tvector-transfers: use extra small unmasked vector.transfer for the slow path\n",
      "        --tile-sizes=<long>                             - Specifies the tile sizes.\n",
      "        --unroll-vector-transfers                       - Enable full unrolling of vector.transfer operations\n",
      "        --vectorize                                     - Rewrite the linalg op as a vector operation.\n",
      "        --vectorize-contraction-to=<string>             - the type of vector op to use for linalg contractions\n",
      "      --test-linalg-fusion-transform-patterns           -   Test Linalg fusion transformation patterns by applying them greedily.\n",
      "      --test-linalg-greedy-fusion                       -   Test Linalg fusion by applying a greedy test transformation.\n",
      "      --test-linalg-hoisting                            -   Test Linalg hoisting functions.\n",
      "        --test-hoist-redundant-transfers                - Test hoisting transfer_read/transfer_write pairs\n",
      "        --test-hoist-view-allocs                        - Test hoisting alloc used by view\n",
      "      --test-linalg-tile-and-fuse                       -   Test Linalg tiling and fusion of a sequence of Linalg operations.\n",
      "        --tile-sizes=<long>                             - Tile sizes to use for ops\n",
      "      --test-linalg-transform-patterns                  -   Test Linalg transformation patterns by applying them greedily.\n",
      "        --test-affine-min-scf-canonicalization-patterns - Test affine-min + scf canonicalization patterns.\n",
      "        --test-linalg-promotion-options                 - Test promotion options\n",
      "        --test-linalg-to-vector-patterns                - Test a set of patterns that rewrite a linalg contraction in vector.contract form\n",
      "        --test-matmul-to-vector-patterns-tile-1d        - Test a fused pass that applies patterns from matmul to vectors via 1-d tiling\n",
      "        --test-matmul-to-vector-patterns-tile-2d        - Test a fused pass that applies patterns from matmul to vectors via 2-d tiling\n",
      "        --test-patterns                                 - Test a mixed set of patterns\n",
      "        --test-tile-and-distribute-options              - Test tile and distribute options\n",
      "        --test-vector-transfer-forwarding-patterns      - Test a fused pass that forwards linalg.copy to vector.transfer\n",
      "      --test-loop-fusion                                -   Tests loop fusion utility functions.\n",
      "      --test-loop-permutation                           -   Tests affine loop permutation utility\n",
      "        --permutation-map=<uint>                        - Specify the loop permutation\n",
      "      --test-loop-unrolling                             -   Tests loop unrolling transformation\n",
      "        --loop-depth=<uint>                             - Loop depth.\n",
      "        --unroll-factor=<ulong>                         - Loop unroll factor.\n",
      "        --unroll-up-to-factor                           - Loop unroll up to factor.\n",
      "      --test-mapping-to-processing-elements             -   test mapping a single loop on a virtual processor grid\n",
      "      --test-matchers                                   -   Test C++ pattern matchers.\n",
      "      --test-memref-bound-check                         -   Check memref access bounds in a Function\n",
      "      --test-memref-dependence-check                    -   Checks dependences between all pairs of memref accesses.\n",
      "      --test-memref-stride-calculation                  -   Test operation constant folding\n",
      "      --test-merge-blocks                               -   Test Merging operation in ConversionPatternRewriter\n",
      "      --test-ml-opt-pass                                -   Test ML-Opt functionality\n",
      "      --test-mlir-reducer                               -   Tests MLIR Reduce tool by generating failures\n",
      "      --test-module-pass                                -   Test a module pass in the pass manager\n",
      "      --test-opaque-loc                                 -   Changes all leaf locations to opaque locations\n",
      "      --test-options-pass                               -   Test options parsing capabilities\n",
      "        --list=<int>                                    - Example list option\n",
      "        --string=<string>                               - Example string option\n",
      "        --string-list=<string>                          - Example string list option\n",
      "      --test-pass-crash                                 -   Test a pass in the pass manager that always crashes\n",
      "      --test-patterns                                   -   Run test dialect patterns\n",
      "      --test-pdl-bytecode-pass                          -   Test PDL ByteCode functionality\n",
      "      --test-print-callgraph                            -   Print the contents of a constructed callgraph.\n",
      "      --test-print-defuse                               -   Test various printing.\n",
      "      --test-print-dominance                            -   Print the dominance information for multiple regions.\n",
      "      --test-print-liveness                             -   Print the contents of a constructed liveness information.\n",
      "      --test-print-nesting                              -   Test various printing.\n",
      "      --test-print-number-of-block-executions           -   Print the contents of a constructed number of executions analysis for all blocks.\n",
      "      --test-print-number-of-operation-executions       -   Print the contents of a constructed number of executions analysis for all operations.\n",
      "      --test-recursive-types                            -   Test support for recursive types\n",
      "      --test-remapped-value                             -   Test public remapped value mechanism in ConversionPatternRewriter\n",
      "      --test-return-type                                -   Run return type functions\n",
      "      --test-scf-for-utils                              -   test scf.for utils\n",
      "      --test-scf-if-utils                               -   test scf.if utils\n",
      "      --test-shape-function-report                      -   Test pass to report associated shape functions\n",
      "      --test-side-effects                               -   Test side effects interfaces\n",
      "      --test-sparsification                             -   Test automatic generation of sparse tensor code\n",
      "        --ind-type=<int>                                - Set the index type\n",
      "        --parallelization-strategy=<int>                - Set the parallelization strategy\n",
      "        --ptr-type=<int>                                - Set the pointer type\n",
      "        --vectorization-strategy=<int>                  - Set the vectorization strategy\n",
      "        --vl=<int>                                      - Set the vector length\n",
      "      --test-spirv-entry-point-abi                      -   Set the spv.entry_point_abi attribute on GPU kernel function within the module, intended for testing only\n",
      "        --workgroup-size=<int>                          - Workgroup size to use for all gpu.func kernels in the module, specified with x-dimension first, y-dimension next and z-dimension last. Unspecified dimensions will be set to 1\n",
      "      --test-spirv-glsl-canonicalization                -   Tests SPIR-V canonicalization patterns for GLSL extension.\n",
      "      --test-spirv-module-combiner                      -   Tests SPIR-V module combiner library\n",
      "      --test-spirv-op-availability                      -   Test SPIR-V op availability\n",
      "      --test-spirv-target-env                           -   Test SPIR-V target environment\n",
      "      --test-stats-pass                                 -   Test pass statistics\n",
      "      --test-symbol-rauw                                -   Test replacement of symbol uses\n",
      "      --test-symbol-uses                                -   Test detection of symbol uses\n",
      "      --test-trait-folder                               -   Run trait folding\n",
      "      --test-type-interfaces                            -   Test type interface support.\n",
      "      --test-vector-contraction-conversion              -   Test conversion patterns that lower contract ops in the vector dialect\n",
      "        --vector-filter-outerproduct                    - Lower vector.contract to vector.outerproduct but not for vectors of size 4.\n",
      "        --vector-flat-transpose                         - Lower 2-D vector.transpose to vector.flat_transpose\n",
      "        --vector-lower-matrix-intrinsics                - Lower vector.contract to llvm.intr.matrix.multiply\n",
      "        --vector-outerproduct                           - Lower vector.contract to vector.outerproduct\n",
      "      --test-vector-distribute-patterns                 -   Test conversion patterns to distribute vector ops in the vector dialect\n",
      "        --distribution-multiplicity=<int>               - Set the multiplicity used for distributing vector\n",
      "      --test-vector-slices-conversion                   -   Test conversion patterns that lower slices ops in the vector dialect\n",
      "      --test-vector-to-forloop                          -   Test conversion patterns to break up a vector op into a for loop\n",
      "        --distribution-multiplicity=<int>               - Set the multiplicity used for distributing vector\n",
      "      --test-vector-to-vector-conversion                -   Test conversion patterns between ops in the vector dialect\n",
      "      --test-vector-transfer-full-partial-split         -   Test conversion patterns to split transfer ops via scf.if + linalg ops\n",
      "        --use-linalg-copy                               - Split using a unmasked vector.transfer + linalg.fill + linalg.copy operations.\n",
      "      --test-vector-transfer-unrolling-patterns         -   Test conversion patterns to unroll transfer ops in the vector dialect\n",
      "      --test-vector-transferop-opt                      -   Test optimization transformations for transfer ops\n",
      "      --test-vector-unrolling-patterns                  -   Test conversion patterns to unroll contract ops in the vector dialect\n",
      "        --unroll-based-on-type                          - Set the unroll factor based on type of the operation\n",
      "      --tosa-make-broadcastable                         -   TOSA rank Reshape to enable Broadcasting\n",
      "      --tosa-test-quant-utils                           -   TOSA Test: Exercise the APIs in QuantUtils.cpp.\n",
      "    Pass Pipelines:\n",
      "      --test-dump-pipeline                              -   Dumps the pipeline build so far for debugging purposes\n",
      "      --test-options-pass-pipeline                      -   Parses options using pass pipeline registration\n",
      "        --list=<int>                                    - Example list option\n",
      "        --string=<string>                               - Example string option\n",
      "        --string-list=<string>                          - Example string list option\n",
      "      --test-pm-nested-pipeline                         -   Test a nested pipeline in the pass manager\n",
      "      --test-textual-pm-nested-pipeline                 -   Test a nested pipeline in the pass manager\n",
      "  --test-legalize-mode=<value>                          - The legalization mode to use with the test driver\n",
      "    =analysis                                           -   Perform an analysis conversion\n",
      "    =full                                               -   Perform a full conversion\n",
      "    =partial                                            -   Perform a partial conversion\n",
      "  --verify-diagnostics                                  - Check that emitted diagnostics match expected-* lines on the corresponding line\n",
      "  --verify-each                                         - Run the verifier after each transformation pass\n",
      "\n",
      "Generic Options:\n",
      "\n",
      "  --help                                                - Display available options (--help-hidden for more)\n",
      "  --help-list                                           - Display list of available options (--help-list-hidden for more)\n",
      "  --version                                             - Display the version of this program\n",
      "\n",
      "affine-super-vectorizer-test options:\n",
      "\n",
      "  --backward-slicing                                    - Enable testing backward static slicing and topological sort functionalities\n",
      "  --compose-maps                                        - Enable testing the composition of AffineMap where each AffineMap in the composition is specified as the affine_map attribute in a constant op.\n",
      "  --forward-slicing                                     - Enable testing forward static slicing and topological sort functionalities\n",
      "  --normalize-maps                                      - Enable testing the normalization of AffineAffineApplyOp where each AffineAffineApplyOp in the composition is a single output operation.\n",
      "  --slicing                                             - Enable testing static slicing and topological sort functionalities\n",
      "  --vector-shape-ratio=<int>                            - Specify the HW vector size for vectorization\n",
      "  --vectorize-affine-loop-nest                          - Enable testing for the 'vectorizeAffineLoopNest' utility by vectorizing the outermost loops found\n",
      "\n",
      "test-loop-fusion options:\n",
      "\n",
      "  --test-loop-fusion-dependence-check                   - Enable testing of loop fusion dependence check\n",
      "  --test-loop-fusion-slice-computation                  - Enable testing of loop fusion slice computation\n",
      "  --test-loop-fusion-transformation                     - Enable testing of loop fusion transformation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "// configuration: --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/x-mlir": [
       "module  {\n",
       "  module @custom_patterns  {\n",
       "  }\n",
       "  module @ir  {\n",
       "    func @rise_fun(%arg0: memref<6x6xf32>, %arg1: memref<6x6xf32>, %arg2: memref<6x6xf32>) {\n",
       "      \"rise.lowering_unit\"() ( {\n",
       "        %0 = \"rise.in\"(%arg1) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32]} : (memref<6x6xf32>) -> !rise.array<6, array<6, scalar<f32>>>\n",
       "        %1 = \"rise.in\"(%arg2) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32]} : (memref<6x6xf32>) -> !rise.array<6, array<6, scalar<f32>>>\n",
       "        %2 = \"rise.transpose\"() {m = #rise.nat<6>, n = #rise.nat<6>, t = #rise.scalar<f32>} : () -> !rise.fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>\n",
       "        %3 = \"rise.apply\"(%2, %1) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32]} : (!rise.fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>, !rise.array<6, array<6, scalar<f32>>>) -> !rise.array<6, array<6, scalar<f32>>>\n",
       "        %4 = \"rise.lambda\"() ( {\n",
       "        ^bb0(%arg3: !rise.array<6, scalar<f32>>):  // no predecessors\n",
       "          %7 = \"rise.lambda\"() ( {\n",
       "          ^bb0(%arg4: !rise.array<6, scalar<f32>>):  // no predecessors\n",
       "            %10 = \"rise.zip\"() {n = #rise.nat<6>, rise.cost = 0 : i32, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<array<6, scalar<f32>> -> fun<array<6, scalar<f32>> -> array<6, tuple<scalar<f32>, scalar<f32>>>>>\n",
       "            %11 = \"rise.apply\"(%10, %arg3, %arg4) {ksc.color = [6.000000e-01 : f32, 1.000000e-01 : f32, 8.000000e-01 : f32], rise.cost = 0 : i32} : (!rise.fun<array<6, scalar<f32>> -> fun<array<6, scalar<f32>> -> array<6, tuple<scalar<f32>, scalar<f32>>>>>, !rise.array<6, scalar<f32>>, !rise.array<6, scalar<f32>>) -> !rise.array<6, tuple<scalar<f32>, scalar<f32>>>\n",
       "            %12 = \"rise.lambda\"() ( {\n",
       "            ^bb0(%arg5: !rise.tuple<scalar<f32>, scalar<f32>>):  // no predecessors\n",
       "              %19 = \"rise.fst\"() {rise.cost = 0 : i32, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>\n",
       "              %20 = \"rise.snd\"() {rise.cost = 0 : i32, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>\n",
       "              %21 = \"rise.apply\"(%19, %arg5) {ksc.color = [0.899999976 : f32, 6.000000e-01 : f32, 2.000000e-01 : f32], rise.cost = 0 : i32} : (!rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>, !rise.tuple<scalar<f32>, scalar<f32>>) -> !rise.scalar<f32>\n",
       "              %22 = \"rise.apply\"(%20, %arg5) {ksc.color = [5.000000e-01 : f32, 1.000000e-01 : f32, 0.899999976 : f32], rise.cost = 0 : i32} : (!rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>, !rise.tuple<scalar<f32>, scalar<f32>>) -> !rise.scalar<f32>\n",
       "              %23 = \"rise.embed\"(%21, %22) ( {\n",
       "              ^bb0(%arg6: f32, %arg7: f32):  // no predecessors\n",
       "                %24 = mulf %arg6, %arg7 {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : f32\n",
       "                \"rise.return\"(%24) {rise.cost = 0 : i32} : (f32) -> ()\n",
       "              }) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : (!rise.scalar<f32>, !rise.scalar<f32>) -> !rise.scalar<f32>\n",
       "              \"rise.return\"(%23) {rise.cost = 0 : i32} : (!rise.scalar<f32>) -> ()\n",
       "            }) {rise.cost = 1 : i32} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>\n",
       "            %13 = \"rise.lambda\"() ( {\n",
       "            ^bb0(%arg5: !rise.scalar<f32>, %arg6: !rise.scalar<f32>):  // no predecessors\n",
       "              %19 = \"rise.embed\"(%arg5, %arg6) ( {\n",
       "              ^bb0(%arg7: f32, %arg8: f32):  // no predecessors\n",
       "                %20 = addf %arg7, %arg8 {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : f32\n",
       "                \"rise.return\"(%20) {rise.cost = 0 : i32} : (f32) -> ()\n",
       "              }) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : (!rise.scalar<f32>, !rise.scalar<f32>) -> !rise.scalar<f32>\n",
       "              \"rise.return\"(%19) {rise.cost = 0 : i32} : (!rise.scalar<f32>) -> ()\n",
       "            }) {rise.cost = 1 : i32} : () -> !rise.fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>>\n",
       "            %14 = \"rise.literal\"() {ksc.color = [6.000000e-01 : f32, 6.000000e-01 : f32, 1.000000e-01 : f32], literal = #rise.lit<0.000000, scalar<f32>>, rise.cost = 0 : i32} : () -> !rise.scalar<f32>\n",
       "            %15 = \"rise.reduceSeq\"() {n = #rise.nat<6>, rise.cost = 0 : i32, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>> -> fun<scalar<f32> -> fun<array<6, scalar<f32>> -> scalar<f32>>>>\n",
       "            %16 = \"rise.lambda\"() ( {\n",
       "            ^bb0(%arg5: !rise.tuple<scalar<f32>, scalar<f32>>, %arg6: !rise.scalar<f32>):  // no predecessors\n",
       "              %19 = \"rise.apply\"(%12, %arg5) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : (!rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>, !rise.tuple<scalar<f32>, scalar<f32>>) -> !rise.scalar<f32>\n",
       "              %20 = \"rise.apply\"(%13, %19, %arg6) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : (!rise.fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>>, !rise.scalar<f32>, !rise.scalar<f32>) -> !rise.scalar<f32>\n",
       "              \"rise.return\"(%20) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 0 : i32} : (!rise.scalar<f32>) -> ()\n",
       "            }) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 2 : i32} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> fun<scalar<f32> -> scalar<f32>>>\n",
       "            %17 = \"rise.reduceSeq\"() {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], n = #rise.nat<6>, rise.cost = 0 : i32, s = #rise.tuple<scalar<f32>, scalar<f32>>, t = #rise.scalar<f32>, to = \"scf\"} : () -> !rise.fun<fun<tuple<scalar<f32>, scalar<f32>> -> fun<scalar<f32> -> scalar<f32>>> -> fun<scalar<f32> -> fun<array<6, tuple<scalar<f32>, scalar<f32>>> -> scalar<f32>>>>\n",
       "            %18 = \"rise.apply\"(%17, %16, %14, %11) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 14 : i32} : (!rise.fun<fun<tuple<scalar<f32>, scalar<f32>> -> fun<scalar<f32> -> scalar<f32>>> -> fun<scalar<f32> -> fun<array<6, tuple<scalar<f32>, scalar<f32>>> -> scalar<f32>>>>, !rise.fun<tuple<scalar<f32>, scalar<f32>> -> fun<scalar<f32> -> scalar<f32>>>, !rise.scalar<f32>, !rise.array<6, tuple<scalar<f32>, scalar<f32>>>) -> !rise.scalar<f32>\n",
       "            \"rise.return\"(%18) {rise.cost = 0 : i32} : (!rise.scalar<f32>) -> ()\n",
       "          }) {rise.cost = 18 : i32} : () -> !rise.fun<array<6, scalar<f32>> -> scalar<f32>>\n",
       "          %8 = \"rise.mapSeq\"() {n = #rise.nat<6>, s = #rise.array<6, scalar<f32>>, t = #rise.scalar<f32>} : () -> !rise.fun<fun<array<6, scalar<f32>> -> scalar<f32>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, scalar<f32>>>>\n",
       "          %9 = \"rise.apply\"(%8, %7, %3) {ksc.color = [8.000000e-01 : f32, 6.000000e-01 : f32, 5.000000e-01 : f32]} : (!rise.fun<fun<array<6, scalar<f32>> -> scalar<f32>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, scalar<f32>>>>, !rise.fun<array<6, scalar<f32>> -> scalar<f32>>, !rise.array<6, array<6, scalar<f32>>>) -> !rise.array<6, scalar<f32>>\n",
       "          \"rise.return\"(%9) : (!rise.array<6, scalar<f32>>) -> ()\n",
       "        }) : () -> !rise.fun<array<6, scalar<f32>> -> array<6, scalar<f32>>>\n",
       "        %5 = \"rise.mapSeq\"() {n = #rise.nat<6>, s = #rise.array<6, scalar<f32>>, t = #rise.array<6, scalar<f32>>} : () -> !rise.fun<fun<array<6, scalar<f32>> -> array<6, scalar<f32>>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>>\n",
       "        %6 = \"rise.apply\"(%5, %4, %0) {ksc.color = [0.899999976 : f32, 0.899999976 : f32, 0.000000e+00 : f32]} : (!rise.fun<fun<array<6, scalar<f32>> -> array<6, scalar<f32>>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>>, !rise.fun<array<6, scalar<f32>> -> array<6, scalar<f32>>>, !rise.array<6, array<6, scalar<f32>>>) -> !rise.array<6, array<6, scalar<f32>>>\n",
       "        \"rise.out\"(%arg0, %6) : (memref<6x6xf32>, !rise.array<6, array<6, scalar<f32>>>) -> ()\n",
       "        \"rise.return\"() : () -> ()\n",
       "      }) : () -> ()\n",
       "      return\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module  {\n",
      "  module @custom_patterns  {\n",
      "  }\n",
      "  module @ir  {\n",
      "    func @rise_fun(%arg0: memref<6x6xf32>, %arg1: memref<6x6xf32>, %arg2: memref<6x6xf32>) {\n",
      "      \"rise.lowering_unit\"() ( {\n",
      "        %0 = \"rise.in\"(%arg1) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32]} : (memref<6x6xf32>) -> !rise.array<6, array<6, scalar<f32>>>\n",
      "        %1 = \"rise.in\"(%arg2) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32]} : (memref<6x6xf32>) -> !rise.array<6, array<6, scalar<f32>>>\n",
      "        %2 = \"rise.transpose\"() {m = #rise.nat<6>, n = #rise.nat<6>, t = #rise.scalar<f32>} : () -> !rise.fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>\n",
      "        %3 = \"rise.apply\"(%2, %1) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32]} : (!rise.fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>, !rise.array<6, array<6, scalar<f32>>>) -> !rise.array<6, array<6, scalar<f32>>>\n",
      "        %4 = \"rise.lambda\"() ( {\n",
      "        ^bb0(%arg3: !rise.array<6, scalar<f32>>):  // no predecessors\n",
      "          %7 = \"rise.lambda\"() ( {\n",
      "          ^bb0(%arg4: !rise.array<6, scalar<f32>>):  // no predecessors\n",
      "            %10 = \"rise.zip\"() {n = #rise.nat<6>, rise.cost = 0 : i32, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<array<6, scalar<f32>> -> fun<array<6, scalar<f32>> -> array<6, tuple<scalar<f32>, scalar<f32>>>>>\n",
      "            %11 = \"rise.apply\"(%10, %arg3, %arg4) {ksc.color = [6.000000e-01 : f32, 1.000000e-01 : f32, 8.000000e-01 : f32], rise.cost = 0 : i32} : (!rise.fun<array<6, scalar<f32>> -> fun<array<6, scalar<f32>> -> array<6, tuple<scalar<f32>, scalar<f32>>>>>, !rise.array<6, scalar<f32>>, !rise.array<6, scalar<f32>>) -> !rise.array<6, tuple<scalar<f32>, scalar<f32>>>\n",
      "            %12 = \"rise.lambda\"() ( {\n",
      "            ^bb0(%arg5: !rise.tuple<scalar<f32>, scalar<f32>>):  // no predecessors\n",
      "              %19 = \"rise.fst\"() {rise.cost = 0 : i32, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>\n",
      "              %20 = \"rise.snd\"() {rise.cost = 0 : i32, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>\n",
      "              %21 = \"rise.apply\"(%19, %arg5) {ksc.color = [0.899999976 : f32, 6.000000e-01 : f32, 2.000000e-01 : f32], rise.cost = 0 : i32} : (!rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>, !rise.tuple<scalar<f32>, scalar<f32>>) -> !rise.scalar<f32>\n",
      "              %22 = \"rise.apply\"(%20, %arg5) {ksc.color = [5.000000e-01 : f32, 1.000000e-01 : f32, 0.899999976 : f32], rise.cost = 0 : i32} : (!rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>, !rise.tuple<scalar<f32>, scalar<f32>>) -> !rise.scalar<f32>\n",
      "              %23 = \"rise.embed\"(%21, %22) ( {\n",
      "              ^bb0(%arg6: f32, %arg7: f32):  // no predecessors\n",
      "                %24 = mulf %arg6, %arg7 {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : f32\n",
      "                \"rise.return\"(%24) {rise.cost = 0 : i32} : (f32) -> ()\n",
      "              }) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : (!rise.scalar<f32>, !rise.scalar<f32>) -> !rise.scalar<f32>\n",
      "              \"rise.return\"(%23) {rise.cost = 0 : i32} : (!rise.scalar<f32>) -> ()\n",
      "            }) {rise.cost = 1 : i32} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>\n",
      "            %13 = \"rise.lambda\"() ( {\n",
      "            ^bb0(%arg5: !rise.scalar<f32>, %arg6: !rise.scalar<f32>):  // no predecessors\n",
      "              %19 = \"rise.embed\"(%arg5, %arg6) ( {\n",
      "              ^bb0(%arg7: f32, %arg8: f32):  // no predecessors\n",
      "                %20 = addf %arg7, %arg8 {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : f32\n",
      "                \"rise.return\"(%20) {rise.cost = 0 : i32} : (f32) -> ()\n",
      "              }) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : (!rise.scalar<f32>, !rise.scalar<f32>) -> !rise.scalar<f32>\n",
      "              \"rise.return\"(%19) {rise.cost = 0 : i32} : (!rise.scalar<f32>) -> ()\n",
      "            }) {rise.cost = 1 : i32} : () -> !rise.fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>>\n",
      "            %14 = \"rise.literal\"() {ksc.color = [6.000000e-01 : f32, 6.000000e-01 : f32, 1.000000e-01 : f32], literal = #rise.lit<0.000000, scalar<f32>>, rise.cost = 0 : i32} : () -> !rise.scalar<f32>\n",
      "            %15 = \"rise.reduceSeq\"() {n = #rise.nat<6>, rise.cost = 0 : i32, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>> -> fun<scalar<f32> -> fun<array<6, scalar<f32>> -> scalar<f32>>>>\n",
      "            %16 = \"rise.lambda\"() ( {\n",
      "            ^bb0(%arg5: !rise.tuple<scalar<f32>, scalar<f32>>, %arg6: !rise.scalar<f32>):  // no predecessors\n",
      "              %19 = \"rise.apply\"(%12, %arg5) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : (!rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>, !rise.tuple<scalar<f32>, scalar<f32>>) -> !rise.scalar<f32>\n",
      "              %20 = \"rise.apply\"(%13, %19, %arg6) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : (!rise.fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>>, !rise.scalar<f32>, !rise.scalar<f32>) -> !rise.scalar<f32>\n",
      "              \"rise.return\"(%20) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 0 : i32} : (!rise.scalar<f32>) -> ()\n",
      "            }) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 2 : i32} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> fun<scalar<f32> -> scalar<f32>>>\n",
      "            %17 = \"rise.reduceSeq\"() {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], n = #rise.nat<6>, rise.cost = 0 : i32, s = #rise.tuple<scalar<f32>, scalar<f32>>, t = #rise.scalar<f32>, to = \"scf\"} : () -> !rise.fun<fun<tuple<scalar<f32>, scalar<f32>> -> fun<scalar<f32> -> scalar<f32>>> -> fun<scalar<f32> -> fun<array<6, tuple<scalar<f32>, scalar<f32>>> -> scalar<f32>>>>\n",
      "            %18 = \"rise.apply\"(%17, %16, %14, %11) {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 14 : i32} : (!rise.fun<fun<tuple<scalar<f32>, scalar<f32>> -> fun<scalar<f32> -> scalar<f32>>> -> fun<scalar<f32> -> fun<array<6, tuple<scalar<f32>, scalar<f32>>> -> scalar<f32>>>>, !rise.fun<tuple<scalar<f32>, scalar<f32>> -> fun<scalar<f32> -> scalar<f32>>>, !rise.scalar<f32>, !rise.array<6, tuple<scalar<f32>, scalar<f32>>>) -> !rise.scalar<f32>\n",
      "            \"rise.return\"(%18) {rise.cost = 0 : i32} : (!rise.scalar<f32>) -> ()\n",
      "          }) {rise.cost = 18 : i32} : () -> !rise.fun<array<6, scalar<f32>> -> scalar<f32>>\n",
      "          %8 = \"rise.mapSeq\"() {n = #rise.nat<6>, s = #rise.array<6, scalar<f32>>, t = #rise.scalar<f32>} : () -> !rise.fun<fun<array<6, scalar<f32>> -> scalar<f32>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, scalar<f32>>>>\n",
      "          %9 = \"rise.apply\"(%8, %7, %3) {ksc.color = [8.000000e-01 : f32, 6.000000e-01 : f32, 5.000000e-01 : f32]} : (!rise.fun<fun<array<6, scalar<f32>> -> scalar<f32>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, scalar<f32>>>>, !rise.fun<array<6, scalar<f32>> -> scalar<f32>>, !rise.array<6, array<6, scalar<f32>>>) -> !rise.array<6, scalar<f32>>\n",
      "          \"rise.return\"(%9) : (!rise.array<6, scalar<f32>>) -> ()\n",
      "        }) : () -> !rise.fun<array<6, scalar<f32>> -> array<6, scalar<f32>>>\n",
      "        %5 = \"rise.mapSeq\"() {n = #rise.nat<6>, s = #rise.array<6, scalar<f32>>, t = #rise.array<6, scalar<f32>>} : () -> !rise.fun<fun<array<6, scalar<f32>> -> array<6, scalar<f32>>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>>\n",
      "        %6 = \"rise.apply\"(%5, %4, %0) {ksc.color = [0.899999976 : f32, 0.899999976 : f32, 0.000000e+00 : f32]} : (!rise.fun<fun<array<6, scalar<f32>> -> array<6, scalar<f32>>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>>, !rise.fun<array<6, scalar<f32>> -> array<6, scalar<f32>>>, !rise.array<6, array<6, scalar<f32>>>) -> !rise.array<6, array<6, scalar<f32>>>\n",
      "        \"rise.out\"(%arg0, %6) : (memref<6x6xf32>, !rise.array<6, array<6, scalar<f32>>>) -> ()\n",
      "        \"rise.return\"() : () -> ()\n",
      "      }) : () -> ()\n",
      "      return\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "out = (\n",
      "\u001b[38;2;229;229;229m\u001b[0m\u001b[38;2;229;229;229mmapSeq\u001b[0m(λ(x0 : !rise.array<6, scalar<f32>> =>\n",
      "    \u001b[38;2;204;153;153m\u001b[0m\u001b[38;2;204;153;153mmapSeq\u001b[0m(λ(x1 : !rise.array<6, scalar<f32>> =>\n",
      "        \u001b[38;2;153;153;153m\u001b[0m\u001b[38;2;153;153;153mreduceSeq\u001b[0m(λ(x2 : !rise.scalar<f32>,x3 : !rise.scalar<f32> =>\n",
      "            \u001b[38;2;127;127;127membed(\u001b[0me4 : f32,e5 : f32 => {\n",
      "                \u001b[38;2;127;127;127mstd.addf\u001b[0m(x4,x5)\n",
      "                }, x2,x3))\n",
      "        ,\u001b[38;2;153;153;153ml(0.000000)\u001b[0m,\u001b[38;2;229;229;229m\u001b[0m\u001b[38;2;229;229;229mmapSeq\u001b[0m(λ(x6 : !rise.tuple<scalar<f32>, scalar<f32>> =>\n",
      "            \u001b[38;2;127;127;127membed(\u001b[0me7 : f32,e8 : f32 => {\n",
      "                \u001b[38;2;127;127;127mstd.mulf\u001b[0m(x7,x8)\n",
      "                }, \u001b[38;2;229;153;153m\u001b[0m\u001b[38;2;229;153;153mfst\u001b[0m(x6),\u001b[38;2;127;25;25m\u001b[0m\u001b[38;2;127;25;25msnd\u001b[0m(x6)))\n",
      "        ,\u001b[38;2;153;25;25m\u001b[0m\u001b[38;2;153;25;25mzip\u001b[0m(x0,x1))))\n",
      "    ,\u001b[38;2;127;127;127m\u001b[0m\u001b[38;2;127;127;127mtranspose\u001b[0m(\u001b[38;2;127;127;127min\u001b[0m)))\n",
      ",\u001b[38;2;229;229;229min\u001b[0m))\n",
      "\n",
      "out = (\n",
      "\u001b[38;2;229;229;229m\u001b[0m\u001b[38;2;229;229;229mmapSeq\u001b[0m(λ(x0 : !rise.array<6, scalar<f32>> =>\n",
      "    \u001b[38;2;204;153;153m\u001b[0m\u001b[38;2;204;153;153mmapSeq\u001b[0m(λ(x1 : !rise.array<6, scalar<f32>> =>\n",
      "        \u001b[38;2;127;127;127m\u001b[0m\u001b[38;2;127;127;127mreduceSeq\u001b[0m(λ(x2 : !rise.tuple<scalar<f32>, scalar<f32>>,x3 : !rise.scalar<f32> =>\n",
      "            \u001b[38;2;127;127;127m\u001b[0mλ(x4 : !rise.scalar<f32>,x5 : !rise.scalar<f32> =>\n",
      "                \u001b[38;2;127;127;127membed(\u001b[0me6 : f32,e7 : f32 => {\n",
      "                    \u001b[38;2;127;127;127mstd.addf\u001b[0m(x6,x7)\n",
      "                    }, x4,x5))\n",
      "            (\u001b[38;2;127;127;127m\u001b[0mλ(x8 : !rise.tuple<scalar<f32>, scalar<f32>> =>\n",
      "                \u001b[38;2;127;127;127membed(\u001b[0me9 : f32,e10 : f32 => {\n",
      "                    \u001b[38;2;127;127;127mstd.mulf\u001b[0m(x9,x10)\n",
      "                    }, \u001b[38;2;229;153;153m\u001b[0m\u001b[38;2;229;153;153mfst\u001b[0m(x8),\u001b[38;2;127;25;25m\u001b[0m\u001b[38;2;127;25;25msnd\u001b[0m(x8)))\n",
      "            (x2),x3))\n",
      "        ,\u001b[38;2;127;127;127ml(0.000000)\u001b[0m,\u001b[38;2;153;25;25m\u001b[0m\u001b[38;2;153;25;25mzip\u001b[0m(x0,x1)))\n",
      "    ,\u001b[38;2;127;127;127m\u001b[0m\u001b[38;2;127;127;127mtranspose\u001b[0m(\u001b[38;2;127;127;127min\u001b[0m)))\n",
      ",\u001b[38;2;229;229;229min\u001b[0m))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// configuration: --test-ml-opt-pass\n",
    "\n",
    "\n",
    "module @custom_patterns {\n",
    "module @color_patterns {\n",
    "  // match for operations which do not have a color attribute and add one\n",
    "  func @matcher(%root : !pdl.operation) {\n",
    "    pdl_interp.apply_constraint \"no_color\"(%root : !pdl.operation) -> ^pat, ^end\n",
    "\n",
    "  ^pat:\n",
    "    pdl_interp.record_match @rewriters::@add_color(%root : !pdl.operation) : benefit(1), loc([%root]) -> ^end\n",
    "\n",
    "  ^end:\n",
    "    pdl_interp.finalize\n",
    "  }\n",
    "  module @rewriters {\n",
    "    func @add_color(%root : !pdl.operation) {\n",
    "      pdl_interp.apply_rewrite \"add_color\" on %root\n",
    "      pdl_interp.finalize\n",
    "    }\n",
    "  }\n",
    "}\n",
    "}\n",
    "\n",
    "module @pdl_patterns {\n",
    "\n",
    "  // fuseReduceMap\n",
    "  // apply reduceSeq f init (mapSeq g array) -> apply reduceSeq compose(f,g) init array\n",
    "  pdl.pattern @fuseReduceMap : benefit(2) {\n",
    "    %mapResT = pdl.type\n",
    "    %applyMapResT = pdl.type\n",
    "    %reduceResT = pdl.type\n",
    "    %applyReduceResT = pdl.type\n",
    "    %g = pdl.input\n",
    "    %array = pdl.input\n",
    "    %f = pdl.input\n",
    "    %init = pdl.input\n",
    "\n",
    "    %map, %mapRes = pdl.operation \"rise.mapSeq\" -> %mapResT\n",
    "    %mapApply, %mapApplyRes = pdl.operation \"rise.apply\"(%mapRes, %g, %array) -> %applyMapResT\n",
    "    %reduce, %reduceRes = pdl.operation \"rise.reduceSeq\" -> %reduceResT\n",
    "    %redApply, %redApplyRes = pdl.operation \"rise.apply\"(%reduceRes, %f, %init, %mapApplyRes) -> %applyReduceResT\n",
    "\n",
    "    pdl.rewrite %redApply with \"fuseReduceMap\"(%f, %init, %g, %array, %map, %mapApply : !pdl.value, !pdl.value, !pdl.value, !pdl.value, !pdl.operation, !pdl.operation)\n",
    "\n",
    "  }\n",
    "\n",
    "}\n",
    "\n",
    "module @ir {\n",
    "func @rise_fun(%arg0: memref<6x6xf32>, %arg1: memref<6x6xf32>, %arg2: memref<6x6xf32>) {\n",
    "  \"rise.lowering_unit\"() ( {\n",
    "    %0 = \"rise.in\"(%arg1) {\"ksc.color\" = [0.5 : f32, 0.5 : f32, 0.5 : f32]} : (memref<6x6xf32>) -> !rise.array<6, array<6, scalar<f32>>>\n",
    "    %1 = \"rise.in\"(%arg2) {\"ksc.color\" = [0.5 : f32, 0.5 : f32, 0.5 : f32]} : (memref<6x6xf32>) -> !rise.array<6, array<6, scalar<f32>>>\n",
    "    %2 = \"rise.transpose\"() {m = #rise.nat<6>, n = #rise.nat<6>, t = #rise.scalar<f32>} : () -> !rise.fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>\n",
    "    %3 = \"rise.apply\"(%2, %1) {\"ksc.color\" = [0.5 : f32, 0.5 : f32, 0.5 : f32]} : (!rise.fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>, !rise.array<6, array<6, scalar<f32>>>) -> !rise.array<6, array<6, scalar<f32>>>\n",
    "    %4 = \"rise.lambda\"() ( {\n",
    "    ^bb0(%arg3: !rise.array<6, scalar<f32>>):  // no predecessors\n",
    "      %7 = \"rise.lambda\"() ( {\n",
    "      ^bb0(%arg4: !rise.array<6, scalar<f32>>):  // no predecessors\n",
    "        %10 = \"rise.zip\"() {n = #rise.nat<6>, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<array<6, scalar<f32>> -> fun<array<6, scalar<f32>> -> array<6, tuple<scalar<f32>, scalar<f32>>>>>\n",
    "        %11 = \"rise.apply\"(%10, %arg3, %arg4) {\"ksc.color\" = [0.6 : f32, 0.1 : f32, 0.8 : f32]} : (!rise.fun<array<6, scalar<f32>> -> fun<array<6, scalar<f32>> -> array<6, tuple<scalar<f32>, scalar<f32>>>>>, !rise.array<6, scalar<f32>>, !rise.array<6, scalar<f32>>) -> !rise.array<6, tuple<scalar<f32>, scalar<f32>>>\n",
    "        %12 = \"rise.lambda\"() ( {\n",
    "        ^bb0(%arg5: !rise.tuple<scalar<f32>, scalar<f32>>):  // no predecessors\n",
    "          %19 = \"rise.fst\"() {s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>\n",
    "          %20 = \"rise.snd\"() {s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>\n",
    "          %21 = \"rise.apply\"(%19, %arg5) {\"ksc.color\" = [0.9 : f32, 0.6 : f32, 0.2 : f32]} : (!rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>, !rise.tuple<scalar<f32>, scalar<f32>>) -> !rise.scalar<f32>\n",
    "          %22 = \"rise.apply\"(%20, %arg5) {\"ksc.color\" = [0.5 : f32, 0.1 : f32, 0.9 : f32]} : (!rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>, !rise.tuple<scalar<f32>, scalar<f32>>) -> !rise.scalar<f32>\n",
    "          %23 = \"rise.embed\"(%21, %22) ( {\n",
    "          ^bb0(%arg6: f32, %arg7: f32):  // no predecessors\n",
    "            %24 = mulf %arg6, %arg7 {\"ksc.color\" = [0.5 : f32, 0.5 : f32, 0.5 : f32]} : f32\n",
    "            \"rise.return\"(%24) : (f32) -> ()\n",
    "          }) {\"ksc.color\" = [0.5 : f32, 0.5 : f32, 0.5 : f32]} : (!rise.scalar<f32>, !rise.scalar<f32>) -> !rise.scalar<f32>\n",
    "          \"rise.return\"(%23) : (!rise.scalar<f32>) -> ()\n",
    "        }) : () -> !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>\n",
    "        %13 = \"rise.mapSeq\"() {n = #rise.nat<6>, s = #rise.tuple<scalar<f32>, scalar<f32>>, t = #rise.scalar<f32>} : () -> !rise.fun<fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>> -> fun<array<6, tuple<scalar<f32>, scalar<f32>>> -> array<6, scalar<f32>>>>\n",
    "        %14 = \"rise.apply\"(%13, %12, %11) {\"ksc.color\" = [0.9 : f32, 0.9 : f32, 0.0 : f32]} : (!rise.fun<fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>> -> fun<array<6, tuple<scalar<f32>, scalar<f32>>> -> array<6, scalar<f32>>>>, !rise.fun<tuple<scalar<f32>, scalar<f32>> -> scalar<f32>>, !rise.array<6, tuple<scalar<f32>, scalar<f32>>>) -> !rise.array<6, scalar<f32>>\n",
    "        %15 = \"rise.lambda\"() ( {\n",
    "        ^bb0(%arg5: !rise.scalar<f32>, %arg6: !rise.scalar<f32>):  // no predecessors\n",
    "          %19 = \"rise.embed\"(%arg5, %arg6) ( {\n",
    "          ^bb0(%arg7: f32, %arg8: f32):  // no predecessors\n",
    "            %20 = addf %arg7, %arg8 {\"ksc.color\" = [0.5 : f32, 0.5 : f32, 0.5 : f32]} : f32\n",
    "            \"rise.return\"(%20) : (f32) -> ()\n",
    "          }) {\"ksc.color\" = [0.5 : f32, 0.5 : f32, 0.5 : f32]} : (!rise.scalar<f32>, !rise.scalar<f32>) -> !rise.scalar<f32>\n",
    "          \"rise.return\"(%19) : (!rise.scalar<f32>) -> ()\n",
    "        }) : () -> !rise.fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>>\n",
    "        %16 = \"rise.literal\"() {literal = #rise.lit<0.000000, scalar<f32>>, \"ksc.color\" = [0.6 : f32, 0.6 : f32, 0.1 : f32]} : () -> !rise.scalar<f32>\n",
    "        %17 = \"rise.reduceSeq\"() {n = #rise.nat<6>, s = #rise.scalar<f32>, t = #rise.scalar<f32>} : () -> !rise.fun<fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>> -> fun<scalar<f32> -> fun<array<6, scalar<f32>> -> scalar<f32>>>>\n",
    "        %18 = \"rise.apply\"(%17, %15, %16, %14) {\"ksc.color\" = [0.6 : f32, 0.6 : f32, 0.1 : f32]} : (!rise.fun<fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>> -> fun<scalar<f32> -> fun<array<6, scalar<f32>> -> scalar<f32>>>>, !rise.fun<scalar<f32> -> fun<scalar<f32> -> scalar<f32>>>, !rise.scalar<f32>, !rise.array<6, scalar<f32>>) -> !rise.scalar<f32>\n",
    "        \"rise.return\"(%18) : (!rise.scalar<f32>) -> ()\n",
    "      }) : () -> !rise.fun<array<6, scalar<f32>> -> scalar<f32>>\n",
    "      %8 = \"rise.mapSeq\"() {n = #rise.nat<6>, s = #rise.array<6, scalar<f32>>, t = #rise.scalar<f32>} : () -> !rise.fun<fun<array<6, scalar<f32>> -> scalar<f32>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, scalar<f32>>>>\n",
    "      %9 = \"rise.apply\"(%8, %7, %3) {\"ksc.color\" = [0.8 : f32, 0.6 : f32, 0.5 : f32]} : (!rise.fun<fun<array<6, scalar<f32>> -> scalar<f32>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, scalar<f32>>>>, !rise.fun<array<6, scalar<f32>> -> scalar<f32>>, !rise.array<6, array<6, scalar<f32>>>) -> !rise.array<6, scalar<f32>>\n",
    "      \"rise.return\"(%9) : (!rise.array<6, scalar<f32>>) -> ()\n",
    "    }) : () -> !rise.fun<array<6, scalar<f32>> -> array<6, scalar<f32>>>\n",
    "    %5 = \"rise.mapSeq\"() {n = #rise.nat<6>, s = #rise.array<6, scalar<f32>>, t = #rise.array<6, scalar<f32>>} : () -> !rise.fun<fun<array<6, scalar<f32>> -> array<6, scalar<f32>>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>>\n",
    "    %6 = \"rise.apply\"(%5, %4, %0) {\"ksc.color\" = [0.9 : f32, 0.9 : f32, 0.0 : f32]} : (!rise.fun<fun<array<6, scalar<f32>> -> array<6, scalar<f32>>> -> fun<array<6, array<6, scalar<f32>>> -> array<6, array<6, scalar<f32>>>>>, !rise.fun<array<6, scalar<f32>> -> array<6, scalar<f32>>>, !rise.array<6, array<6, scalar<f32>>>) -> !rise.array<6, array<6, scalar<f32>>>\n",
    "    \"rise.out\"(%arg0, %6) : (memref<6x6xf32>, !rise.array<6, array<6, scalar<f32>>>) -> ()\n",
    "    \"rise.return\"() : () -> ()\n",
    "  }) : () -> ()\n",
    "  return\n",
    "}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/x-mlir": [
       "module  {\n",
       "  module @custom_patterns  {\n",
       "  }\n",
       "  module @ir  {\n",
       "    func @rise_fun(%arg0: memref<6x6xf32>, %arg1: memref<6x6xf32>, %arg2: memref<6x6xf32>) {\n",
       "      %cst = constant 0.000000e+00 : f32\n",
       "      %c0 = constant 0 : index\n",
       "      %c6 = constant 6 : index\n",
       "      %c1 = constant 1 : index\n",
       "      scf.for %arg3 = %c0 to %c6 step %c1 {\n",
       "        scf.for %arg4 = %c0 to %c6 step %c1 {\n",
       "          %0 = alloc() : memref<f32>\n",
       "          store %cst, %0[] : memref<f32>\n",
       "          scf.for %arg5 = %c0 to %c6 step %c1 {\n",
       "            %2 = load %arg1[%arg3, %arg5] : memref<6x6xf32>\n",
       "            %3 = load %arg2[%arg5, %arg4] : memref<6x6xf32>\n",
       "            %4 = mulf %2, %3 {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : f32\n",
       "            %5 = load %0[] : memref<f32>\n",
       "            %6 = addf %5, %4 {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : f32\n",
       "            store %6, %0[] : memref<f32>\n",
       "          }\n",
       "          %1 = load %0[] : memref<f32>\n",
       "          store %1, %arg0[%arg3, %arg4] : memref<6x6xf32>\n",
       "        }\n",
       "      }\n",
       "      return\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module  {\n",
      "  module @custom_patterns  {\n",
      "  }\n",
      "  module @ir  {\n",
      "    func @rise_fun(%arg0: memref<6x6xf32>, %arg1: memref<6x6xf32>, %arg2: memref<6x6xf32>) {\n",
      "      %cst = constant 0.000000e+00 : f32\n",
      "      %c0 = constant 0 : index\n",
      "      %c6 = constant 6 : index\n",
      "      %c1 = constant 1 : index\n",
      "      scf.for %arg3 = %c0 to %c6 step %c1 {\n",
      "        scf.for %arg4 = %c0 to %c6 step %c1 {\n",
      "          %0 = alloc() : memref<f32>\n",
      "          store %cst, %0[] : memref<f32>\n",
      "          scf.for %arg5 = %c0 to %c6 step %c1 {\n",
      "            %2 = load %arg1[%arg3, %arg5] : memref<6x6xf32>\n",
      "            %3 = load %arg2[%arg5, %arg4] : memref<6x6xf32>\n",
      "            %4 = mulf %2, %3 {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : f32\n",
      "            %5 = load %0[] : memref<f32>\n",
      "            %6 = addf %5, %4 {ksc.color = [5.000000e-01 : f32, 5.000000e-01 : f32, 5.000000e-01 : f32], rise.cost = 1 : i32} : f32\n",
      "            store %6, %0[] : memref<f32>\n",
      "          }\n",
      "          %1 = load %0[] : memref<f32>\n",
      "          store %1, %arg0[%arg3, %arg4] : memref<6x6xf32>\n",
      "        }\n",
      "      }\n",
      "      return\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "// configuration: --pass-pipeline='module(func(convert-rise-to-imperative,canonicalize))'\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MlirOpt",
   "language": "mlir",
   "name": "mlir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "mlir"
   },
   "file_extension": ".mlir",
   "mimetype": "text/x-mlir",
   "name": "mlir",
   "pygments_lexer": "text"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
